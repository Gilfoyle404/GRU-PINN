{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d87dee3e-6e38-452d-8f98-133763138eb1",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fcea08b-b8d1-4a00-b85c-bcd8ec2c3e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Total sequences: 1038, Shape: (1038, 128, 3)\n",
      "Train: 830 | Test: 208\n",
      "Device: cpu\n",
      "\n",
      "Parameters: 200,321\n",
      "\n",
      "Training...\n",
      "Epoch 010 | Train Loss: 0.001991 | Test Loss: 0.001479\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 146\u001b[39m\n\u001b[32m    144\u001b[39m xb, yb = xb.to(device), yb.to(device)\n\u001b[32m    145\u001b[39m optimizer.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m pred = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    147\u001b[39m loss = loss_fn(pred, yb)\n\u001b[32m    148\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/jawaharram/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/jawaharram/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 125\u001b[39m, in \u001b[36mLSTM_SOC.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     out, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    126\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fc(out)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/jawaharram/lib/python3.11/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/jawaharram/lib/python3.11/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/jawaharram/lib/python3.11/site-packages/torch/nn/modules/rnn.py:1127\u001b[39m, in \u001b[36mLSTM.forward\u001b[39m\u001b[34m(self, input, hx)\u001b[39m\n\u001b[32m   1124\u001b[39m         hx = \u001b[38;5;28mself\u001b[39m.permute_hidden(hx, sorted_indices)\n\u001b[32m   1126\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1127\u001b[39m     result = \u001b[43m_VF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1128\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1129\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1130\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1131\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1132\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1133\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1134\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1135\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1136\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1137\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1138\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1139\u001b[39m     result = _VF.lstm(\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   1141\u001b[39m         batch_sizes,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1148\u001b[39m         \u001b[38;5;28mself\u001b[39m.bidirectional,\n\u001b[32m   1149\u001b[39m     )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# -------------------- Data Loading --------------------\n",
    "data = scipy.io.loadmat('Oxford_Battery_Degradation_Dataset_1.mat')\n",
    "\n",
    "def soc_from_q(q, phase):\n",
    "    \"\"\"Compute SOC% from charge trace.\"\"\"\n",
    "    q0, q1 = float(q[0]), float(q[-1])\n",
    "    if np.isclose(q1, q0):\n",
    "        return None\n",
    "    qn = (q - q0) / (q1 - q0)\n",
    "    if phase == 'C1ch':\n",
    "        return 100.0 * np.clip(qn, 0, 1)\n",
    "    elif phase == 'C1dc':\n",
    "        return 100.0 * (1.0 - np.clip(qn, 0, 1))\n",
    "    return None\n",
    "\n",
    "def extract_sequences(data, L=128):\n",
    "    \"\"\"Extract V, T, I features and SOC labels.\"\"\"\n",
    "    X_list, y_list, phase_list = [], [], []\n",
    "    \n",
    "    for ci in range(1, 9):\n",
    "        cell = data[f'Cell{ci}']\n",
    "        for cyc_name in sorted(cell.dtype.names, key=lambda s: int(s[3:])):\n",
    "            cyc = cell[cyc_name][0, 0]\n",
    "            for phase in ['C1ch', 'C1dc']:\n",
    "                if phase not in cyc.dtype.names:\n",
    "                    continue\n",
    "                blk = cyc[phase][0, 0]\n",
    "                if not all(k in blk.dtype.names for k in ['t','v','q']):\n",
    "                    continue\n",
    "                \n",
    "                t = blk['t'][0,0].ravel().astype(float)\n",
    "                v = blk['v'][0,0].ravel().astype(float)\n",
    "                q = blk['q'][0,0].ravel().astype(float)\n",
    "                \n",
    "                if t.size < 5:\n",
    "                    continue\n",
    "                \n",
    "                # Temperature (fill missing with forward/backward fill)\n",
    "                if 'T' in blk.dtype.names:\n",
    "                    T = blk['T'][0,0].ravel().astype(float)\n",
    "                else:\n",
    "                    T = np.full_like(t, 25.0)\n",
    "                T = pd.Series(T).ffill().bfill().values\n",
    "                \n",
    "                # Current (use defaults if missing)\n",
    "                if 'i' in blk.dtype.names:\n",
    "                    I = blk['i'][0,0].ravel().astype(float)\n",
    "                else:\n",
    "                    I = np.full_like(t, 0.74 if phase == 'C1ch' else -0.74)\n",
    "                \n",
    "                soc = soc_from_q(q, phase)\n",
    "                if soc is None:\n",
    "                    continue\n",
    "                \n",
    "                # Resample to fixed length L\n",
    "                t_new = np.linspace(t[0], t[-1], L)\n",
    "                v_new = np.interp(t_new, t, v)\n",
    "                T_new = np.interp(t_new, t, T)\n",
    "                I_new = np.interp(t_new, t, I)\n",
    "                y_new = np.interp(t_new, t, soc)\n",
    "                \n",
    "                X = np.stack([v_new, T_new, I_new], axis=-1)  # [L, 3]\n",
    "                y = y_new[:, None]  # [L, 1]\n",
    "                \n",
    "                X_list.append(X)\n",
    "                y_list.append(y)\n",
    "                phase_list.append(phase)  # Track charging vs discharging\n",
    "    \n",
    "    return np.array(X_list), np.array(y_list), np.array(phase_list)\n",
    "\n",
    "# -------------------- Prepare Data --------------------\n",
    "print(\"Loading data...\")\n",
    "X, y, phases = extract_sequences(data, L=128)\n",
    "print(f\"Total sequences: {len(X)}, Shape: {X.shape}\")\n",
    "\n",
    "# Train/test split (80/20)\n",
    "n_train = int(0.8 * len(X))\n",
    "X_train, X_test = X[:n_train], X[n_train:]\n",
    "y_train, y_test = y[:n_train], y[n_train:]\n",
    "phases_test = phases[n_train:]\n",
    "\n",
    "# Normalize features\n",
    "mu = X_train.reshape(-1, X_train.shape[-1]).mean(axis=0)\n",
    "sd = X_train.reshape(-1, X_train.shape[-1]).std(axis=0) + 1e-8\n",
    "X_train = (X_train - mu) / sd\n",
    "X_test = (X_test - mu) / sd\n",
    "\n",
    "# Normalize labels to [0, 1]\n",
    "y_train_norm = y_train / 100.0\n",
    "y_test_norm = y_test / 100.0\n",
    "\n",
    "print(f\"Train: {len(X_train)} | Test: {len(X_test)}\")\n",
    "\n",
    "# -------------------- DataLoaders --------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\\n\")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                  torch.tensor(y_train_norm, dtype=torch.float32)),\n",
    "    batch_size=32, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    TensorDataset(torch.tensor(X_test, dtype=torch.float32),\n",
    "                  torch.tensor(y_test_norm, dtype=torch.float32)),\n",
    "    batch_size=32, shuffle=False)\n",
    "\n",
    "# -------------------- LSTM Model --------------------\n",
    "class LSTM_SOC(nn.Module):\n",
    "    def __init__(self, input_dim=3, hidden=128, layers=2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, hidden, num_layers=layers, \n",
    "                           batch_first=True, dropout=0.2)\n",
    "        self.fc = nn.Linear(hidden, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        return self.fc(out)\n",
    "\n",
    "model = LSTM_SOC(input_dim=3, hidden=128, layers=2).to(device)\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.parameters()):,}\\n\")\n",
    "\n",
    "# -------------------- Training --------------------\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "epochs = 100\n",
    "best_loss = float('inf')\n",
    "\n",
    "print(\"Training...\")\n",
    "for epoch in range(epochs):\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb)\n",
    "        loss = loss_fn(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * xb.size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    # Validate\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            test_loss += loss_fn(model(xb), yb).item() * xb.size(0)\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    # Save best model\n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        torch.save(model.state_dict(), 'best_lstm.pt')\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1:03d} | Train Loss: {train_loss:.6f} | Test Loss: {test_loss:.6f}\")\n",
    "\n",
    "print(f\"\\nBest Test Loss: {best_loss:.6f}\")\n",
    "\n",
    "# -------------------- Validation --------------------\n",
    "model.load_state_dict(torch.load('best_lstm.pt'))\n",
    "model.eval()\n",
    "\n",
    "# Get predictions\n",
    "predictions, actuals = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        pred = model(xb).cpu().numpy()\n",
    "        predictions.append(pred)\n",
    "        actuals.append(yb.numpy())\n",
    "\n",
    "predictions = np.concatenate(predictions) * 100  # Convert back to %\n",
    "actuals = np.concatenate(actuals) * 100\n",
    "\n",
    "# Calculate overall metrics\n",
    "mae = np.mean(np.abs(predictions - actuals))\n",
    "rmse = np.sqrt(np.mean((predictions - actuals)**2))\n",
    "max_error = np.max(np.abs(predictions - actuals))\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Overall Validation Metrics:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"MAE:        {mae:.4f}%\")\n",
    "print(f\"RMSE:       {rmse:.4f}%\")\n",
    "print(f\"Max Error:  {max_error:.4f}%\")\n",
    "\n",
    "# -------------------- SOC Range Analysis --------------------\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SOC Range Analysis\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Define SOC ranges to test\n",
    "soc_ranges = [\n",
    "    (0, 30, \"Low SOC (0-30%)\"),\n",
    "    (30, 60, \"Mid SOC (30-60%)\"),\n",
    "    (60, 90, \"High SOC (60-90%)\"),\n",
    "    (0, 100, \"Full Range (0-100%)\")\n",
    "]\n",
    "\n",
    "range_metrics = []\n",
    "\n",
    "for soc_min, soc_max, range_name in soc_ranges:\n",
    "    # Filter predictions and actuals for this SOC range\n",
    "    mask = (actuals >= soc_min) & (actuals <= soc_max)\n",
    "    \n",
    "    if np.sum(mask) == 0:\n",
    "        print(f\"\\n{range_name}: No data points in this range\")\n",
    "        continue\n",
    "    \n",
    "    range_preds = predictions[mask]\n",
    "    range_actuals = actuals[mask]\n",
    "    \n",
    "    # Calculate metrics for this range\n",
    "    range_mae = np.mean(np.abs(range_preds - range_actuals))\n",
    "    range_rmse = np.sqrt(np.mean((range_preds - range_actuals)**2))\n",
    "    range_max_error = np.max(np.abs(range_preds - range_actuals))\n",
    "    n_points = np.sum(mask)\n",
    "    \n",
    "    range_metrics.append({\n",
    "        'Range': range_name,\n",
    "        'MAE': range_mae,\n",
    "        'RMSE': range_rmse,\n",
    "        'Max Error': range_max_error,\n",
    "        'N Points': n_points\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{range_name}:\")\n",
    "    print(f\"  Points:     {n_points:,}\")\n",
    "    print(f\"  MAE:        {range_mae:.4f}%\")\n",
    "    print(f\"  RMSE:       {range_rmse:.4f}%\")\n",
    "    print(f\"  Max Error:  {range_max_error:.4f}%\")\n",
    "\n",
    "# Create DataFrame for easier visualization\n",
    "metrics_df = pd.DataFrame(range_metrics)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Summary Table:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(metrics_df.to_string(index=False))\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# -------------------- Phase-specific Analysis --------------------\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Charging vs Discharging Analysis\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "phase_metrics = []\n",
    "\n",
    "for phase_type in ['C1ch', 'C1dc']:\n",
    "    phase_name = \"Charging\" if phase_type == 'C1ch' else \"Discharging\"\n",
    "    \n",
    "    # Get indices for this phase\n",
    "    phase_mask = phases_test == phase_type\n",
    "    \n",
    "    if np.sum(phase_mask) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Get predictions for this phase\n",
    "    phase_preds = predictions[phase_mask]\n",
    "    phase_actuals = actuals[phase_mask]\n",
    "    \n",
    "    # Overall phase metrics\n",
    "    phase_mae = np.mean(np.abs(phase_preds - phase_actuals))\n",
    "    phase_rmse = np.sqrt(np.mean((phase_preds - phase_actuals)**2))\n",
    "    \n",
    "    print(f\"\\n{phase_name}:\")\n",
    "    print(f\"  Sequences:  {np.sum(phase_mask)}\")\n",
    "    print(f\"  MAE:        {phase_mae:.4f}%\")\n",
    "    print(f\"  RMSE:       {phase_rmse:.4f}%\")\n",
    "    \n",
    "    # Break down by SOC ranges\n",
    "    for soc_min, soc_max, range_name in soc_ranges[:3]:  # Only low, mid, high\n",
    "        range_mask = (phase_actuals >= soc_min) & (phase_actuals <= soc_max)\n",
    "        \n",
    "        if np.sum(range_mask) > 0:\n",
    "            sub_preds = phase_preds[range_mask]\n",
    "            sub_actuals = phase_actuals[range_mask]\n",
    "            sub_mae = np.mean(np.abs(sub_preds - sub_actuals))\n",
    "            sub_rmse = np.sqrt(np.mean((sub_preds - sub_actuals)**2))\n",
    "            \n",
    "            print(f\"    {range_name}:\")\n",
    "            print(f\"      Points: {np.sum(range_mask):,} | MAE: {sub_mae:.4f}% | RMSE: {sub_rmse:.4f}%\")\n",
    "            \n",
    "            phase_metrics.append({\n",
    "                'Phase': phase_name,\n",
    "                'Range': range_name,\n",
    "                'MAE': sub_mae,\n",
    "                'RMSE': sub_rmse,\n",
    "                'N Points': np.sum(range_mask)\n",
    "            })\n",
    "\n",
    "# -------------------- Range-specific Visualization --------------------\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Plot metrics comparison\n",
    "ax = axes[0, 0]\n",
    "x_pos = np.arange(len(range_metrics))\n",
    "ax.bar(x_pos, [m['MAE'] for m in range_metrics], alpha=0.7, color='steelblue')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([m['Range'].split('(')[0].strip() for m in range_metrics], rotation=45, ha='right')\n",
    "ax.set_ylabel('MAE (%)')\n",
    "ax.set_title('MAE by SOC Range', fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "ax = axes[0, 1]\n",
    "ax.bar(x_pos, [m['RMSE'] for m in range_metrics], alpha=0.7, color='coral')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([m['Range'].split('(')[0].strip() for m in range_metrics], rotation=45, ha='right')\n",
    "ax.set_ylabel('RMSE (%)')\n",
    "ax.set_title('RMSE by SOC Range', fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "ax = axes[0, 2]\n",
    "ax.bar(x_pos, [m['Max Error'] for m in range_metrics], alpha=0.7, color='lightcoral')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([m['Range'].split('(')[0].strip() for m in range_metrics], rotation=45, ha='right')\n",
    "ax.set_ylabel('Max Error (%)')\n",
    "ax.set_title('Max Error by SOC Range', fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot error distribution by range\n",
    "for idx, (soc_min, soc_max, range_name) in enumerate(soc_ranges[:3]):\n",
    "    ax = axes[1, idx]\n",
    "    mask = (actuals >= soc_min) & (actuals <= soc_max)\n",
    "    \n",
    "    if np.sum(mask) > 0:\n",
    "        range_errors = (predictions[mask] - actuals[mask]).flatten()\n",
    "        ax.hist(range_errors, bins=30, edgecolor='black', alpha=0.7, color='teal')\n",
    "        ax.axvline(0, color='red', linestyle='--', linewidth=2, label='Zero Error')\n",
    "        ax.set_xlabel('Error (%)')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.set_title(f'{range_name}\\nMean Error: {np.mean(range_errors):.3f}%', fontweight='bold')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('SOC Range Analysis', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -------------------- Phase-specific Visualization --------------------\n",
    "if len(phase_metrics) > 0:\n",
    "    phase_df = pd.DataFrame(phase_metrics)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Grouped bar chart for MAE\n",
    "    ax = axes[0]\n",
    "    ranges_unique = phase_df['Range'].unique()\n",
    "    x = np.arange(len(ranges_unique))\n",
    "    width = 0.35\n",
    "    \n",
    "    charging_data = phase_df[phase_df['Phase'] == 'Charging']\n",
    "    discharging_data = phase_df[phase_df['Phase'] == 'Discharging']\n",
    "    \n",
    "    charge_mae = [charging_data[charging_data['Range'] == r]['MAE'].values[0] \n",
    "                  if len(charging_data[charging_data['Range'] == r]) > 0 else 0 \n",
    "                  for r in ranges_unique]\n",
    "    discharge_mae = [discharging_data[discharging_data['Range'] == r]['MAE'].values[0] \n",
    "                     if len(discharging_data[discharging_data['Range'] == r]) > 0 else 0 \n",
    "                     for r in ranges_unique]\n",
    "    \n",
    "    ax.bar(x - width/2, charge_mae, width, label='Charging', alpha=0.8, color='green')\n",
    "    ax.bar(x + width/2, discharge_mae, width, label='Discharging', alpha=0.8, color='orange')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([r.split('(')[0].strip() for r in ranges_unique], rotation=45, ha='right')\n",
    "    ax.set_ylabel('MAE (%)')\n",
    "    ax.set_title('MAE: Charging vs Discharging by SOC Range', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Grouped bar chart for RMSE\n",
    "    ax = axes[1]\n",
    "    charge_rmse = [charging_data[charging_data['Range'] == r]['RMSE'].values[0] \n",
    "                   if len(charging_data[charging_data['Range'] == r]) > 0 else 0 \n",
    "                   for r in ranges_unique]\n",
    "    discharge_rmse = [discharging_data[discharging_data['Range'] == r]['RMSE'].values[0] \n",
    "                      if len(discharging_data[discharging_data['Range'] == r]) > 0 else 0 \n",
    "                      for r in ranges_unique]\n",
    "    \n",
    "    ax.bar(x - width/2, charge_rmse, width, label='Charging', alpha=0.8, color='green')\n",
    "    ax.bar(x + width/2, discharge_rmse, width, label='Discharging', alpha=0.8, color='orange')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([r.split('(')[0].strip() for r in ranges_unique], rotation=45, ha='right')\n",
    "    ax.set_ylabel('RMSE (%)')\n",
    "    ax.set_title('RMSE: Charging vs Discharging by SOC Range', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -------------------- Partial Curve Testing --------------------\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Testing on Partial Charge/Discharge Curves\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "def create_partial_curve(X_seq, y_seq, soc_start, soc_end):\n",
    "    \"\"\"\n",
    "    Extract a partial curve from a full charge/discharge sequence.\n",
    "    \n",
    "    Args:\n",
    "        X_seq: Input features [L, 3]\n",
    "        y_seq: SOC labels [L, 1]\n",
    "        soc_start: Starting SOC%\n",
    "        soc_end: Ending SOC%\n",
    "    \n",
    "    Returns:\n",
    "        Partial X, y sequences\n",
    "    \"\"\"\n",
    "    soc_values = y_seq[:, 0]\n",
    "    \n",
    "    # Find indices where SOC is within the range\n",
    "    if soc_start < soc_end:  # Charging direction\n",
    "        mask = (soc_values >= soc_start) & (soc_values <= soc_end)\n",
    "    else:  # Discharging direction\n",
    "        mask = (soc_values <= soc_start) & (soc_values >= soc_end)\n",
    "    \n",
    "    if np.sum(mask) < 10:  # Need at least 10 points\n",
    "        return None, None\n",
    "    \n",
    "    indices = np.where(mask)[0]\n",
    "    start_idx, end_idx = indices[0], indices[-1] + 1\n",
    "    \n",
    "    return X_seq[start_idx:end_idx], y_seq[start_idx:end_idx]\n",
    "\n",
    "# Define partial curve test cases\n",
    "partial_curve_tests = [\n",
    "    # Charging scenarios\n",
    "    (0, 30, 'C1ch', 'Charge 0-30%'),\n",
    "    (30, 60, 'C1ch', 'Charge 30-60%'),\n",
    "    (60, 90, 'C1ch', 'Charge 60-90%'),\n",
    "    (20, 80, 'C1ch', 'Charge 20-80%'),\n",
    "    \n",
    "    # Discharging scenarios\n",
    "    (100, 70, 'C1dc', 'Discharge 100-70%'),\n",
    "    (70, 40, 'C1dc', 'Discharge 70-40%'),\n",
    "    (40, 10, 'C1dc', 'Discharge 40-10%'),\n",
    "    (80, 20, 'C1dc', 'Discharge 80-20%'),\n",
    "]\n",
    "\n",
    "partial_results = []\n",
    "\n",
    "for soc_start, soc_end, phase_type, test_name in partial_curve_tests:\n",
    "    # Find test sequences of the right phase\n",
    "    phase_mask = phases_test == phase_type\n",
    "    phase_indices = np.where(phase_mask)[0]\n",
    "    \n",
    "    if len(phase_indices) == 0:\n",
    "        print(f\"\\n{test_name}: No {phase_type} sequences available\")\n",
    "        continue\n",
    "    \n",
    "    # Process multiple sequences for this test case\n",
    "    test_preds, test_actuals = [], []\n",
    "    valid_sequences = 0\n",
    "    \n",
    "    for idx in phase_indices[:50]:  # Test on up to 50 sequences\n",
    "        X_seq = X_test[idx]\n",
    "        y_seq = y_test[idx]\n",
    "        \n",
    "        # Create partial curve\n",
    "        X_partial, y_partial = create_partial_curve(X_seq, y_seq, soc_start, soc_end)\n",
    "        \n",
    "        if X_partial is None:\n",
    "            continue\n",
    "        \n",
    "        valid_sequences += 1\n",
    "        \n",
    "        # Get prediction for partial curve\n",
    "        with torch.no_grad():\n",
    "            x_input = torch.tensor(X_partial[np.newaxis, :, :], dtype=torch.float32, device=device)\n",
    "            pred = model(x_input).cpu().numpy()[0, :, 0] * 100\n",
    "        \n",
    "        true = y_partial[:, 0]\n",
    "        \n",
    "        test_preds.append(pred)\n",
    "        test_actuals.append(true)\n",
    "    \n",
    "    if valid_sequences == 0:\n",
    "        print(f\"\\n{test_name}: No valid partial curves found in range\")\n",
    "        continue\n",
    "    \n",
    "    # Concatenate all predictions\n",
    "    all_preds = np.concatenate(test_preds)\n",
    "    all_actuals = np.concatenate(test_actuals)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = np.mean(np.abs(all_preds - all_actuals))\n",
    "    rmse = np.sqrt(np.mean((all_preds - all_actuals)**2))\n",
    "    max_error = np.max(np.abs(all_preds - all_actuals))\n",
    "    \n",
    "    partial_results.append({\n",
    "        'Test': test_name,\n",
    "        'Phase': phase_type,\n",
    "        'SOC Range': f\"{soc_start}-{soc_end}%\",\n",
    "        'Sequences': valid_sequences,\n",
    "        'Points': len(all_preds),\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'Max Error': max_error\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{test_name}:\")\n",
    "    print(f\"  Valid Sequences: {valid_sequences}\")\n",
    "    print(f\"  Total Points:    {len(all_preds):,}\")\n",
    "    print(f\"  MAE:             {mae:.4f}%\")\n",
    "    print(f\"  RMSE:            {rmse:.4f}%\")\n",
    "    print(f\"  Max Error:       {max_error:.4f}%\")\n",
    "\n",
    "# Create summary table\n",
    "if len(partial_results) > 0:\n",
    "    partial_df = pd.DataFrame(partial_results)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Partial Curve Testing Summary:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(partial_df.to_string(index=False))\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "# -------------------- Partial Curve Visualization --------------------\n",
    "print(\"\\nGenerating partial curve visualizations...\")\n",
    "\n",
    "fig, axes = plt.subplots(4, 2, figsize=(14, 16))\n",
    "\n",
    "# Select interesting partial curve examples\n",
    "visualization_tests = [\n",
    "    (0, 30, 'C1ch', 'Charge 0-30%', 0, 0),\n",
    "    (30, 60, 'C1ch', 'Charge 30-60%', 0, 1),\n",
    "    (60, 90, 'C1ch', 'Charge 60-90%', 1, 0),\n",
    "    (20, 80, 'C1ch', 'Charge 20-80%', 1, 1),\n",
    "    (100, 70, 'C1dc', 'Discharge 100-70%', 2, 0),\n",
    "    (70, 40, 'C1dc', 'Discharge 70-40%', 2, 1),\n",
    "    (40, 10, 'C1dc', 'Discharge 40-10%', 3, 0),\n",
    "    (80, 20, 'C1dc', 'Discharge 80-20%', 3, 1),\n",
    "]\n",
    "\n",
    "for soc_start, soc_end, phase_type, test_name, row, col in visualization_tests:\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    # Find a suitable test sequence\n",
    "    phase_mask = phases_test == phase_type\n",
    "    phase_indices = np.where(phase_mask)[0]\n",
    "    \n",
    "    found = False\n",
    "    for idx in phase_indices[:100]:  # Search through sequences\n",
    "        X_seq = X_test[idx]\n",
    "        y_seq = y_test[idx]\n",
    "        \n",
    "        # Create partial curve\n",
    "        X_partial, y_partial = create_partial_curve(X_seq, y_seq, soc_start, soc_end)\n",
    "        \n",
    "        if X_partial is None or len(X_partial) < 10:\n",
    "            continue\n",
    "        \n",
    "        # Get prediction\n",
    "        with torch.no_grad():\n",
    "            x_input = torch.tensor(X_partial[np.newaxis, :, :], dtype=torch.float32, device=device)\n",
    "            pred = model(x_input).cpu().numpy()[0, :, 0] * 100\n",
    "        \n",
    "        true = y_partial[:, 0]\n",
    "        error = np.abs(true - pred)\n",
    "        mae = np.mean(error)\n",
    "        max_error = np.max(error)\n",
    "        \n",
    "        # Plot\n",
    "        time_steps = np.arange(len(true))\n",
    "        ax.plot(time_steps, true, 'b-', linewidth=2.5, label='True SOC', alpha=0.8)\n",
    "        ax.plot(time_steps, pred, 'r--', linewidth=2, label='Predicted SOC', alpha=0.8)\n",
    "        ax.fill_between(time_steps, true, pred, alpha=0.2, color='orange')\n",
    "        \n",
    "        # Add horizontal lines for SOC range\n",
    "        ax.axhline(soc_start, color='green', linestyle=':', linewidth=1.5, alpha=0.7, label=f'Start: {soc_start}%')\n",
    "        if phase_type == 'C1ch':\n",
    "            ax.axhline(soc_end, color='red', linestyle=':', linewidth=1.5, alpha=0.7, label=f'End: {soc_end}%')\n",
    "        else:\n",
    "            ax.axhline(soc_end, color='red', linestyle=':', linewidth=1.5, alpha=0.7, label=f'End: {soc_end}%')\n",
    "        \n",
    "        ax.set_title(f'{test_name}\\nMAE: {mae:.2f}% | Max Error: {max_error:.2f}%', \n",
    "                     fontsize=10, fontweight='bold')\n",
    "        ax.set_xlabel('Time Step', fontsize=9)\n",
    "        ax.set_ylabel('SOC (%)', fontsize=9)\n",
    "        ax.legend(fontsize=7, loc='best')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_ylim(max(0, min(soc_start, soc_end) - 10), \n",
    "                    min(100, max(soc_start, soc_end) + 10))\n",
    "        \n",
    "        found = True\n",
    "        break\n",
    "    \n",
    "    if not found:\n",
    "        ax.text(0.5, 0.5, f'No valid\\n{test_name}\\ndata found',\n",
    "               ha='center', va='center', fontsize=10, transform=ax.transAxes)\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "plt.suptitle('LSTM Performance on Partial Charge/Discharge Curves', \n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -------------------- Comparison: Full vs Partial Curves --------------------\n",
    "if len(partial_results) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Separate charging and discharging\n",
    "    charging_partial = partial_df[partial_df['Phase'] == 'C1ch']\n",
    "    discharging_partial = partial_df[partial_df['Phase'] == 'C1dc']\n",
    "    \n",
    "    # Plot MAE comparison\n",
    "    ax = axes[0]\n",
    "    if len(charging_partial) > 0:\n",
    "        x_charge = np.arange(len(charging_partial))\n",
    "        ax.bar(x_charge - 0.2, charging_partial['MAE'], 0.4, \n",
    "               label='Charging', alpha=0.8, color='green')\n",
    "    if len(discharging_partial) > 0:\n",
    "        x_discharge = np.arange(len(discharging_partial))\n",
    "        ax.bar(x_discharge + 0.2, discharging_partial['MAE'], 0.4, \n",
    "               label='Discharging', alpha=0.8, color='orange')\n",
    "    \n",
    "    all_tests = pd.concat([charging_partial, discharging_partial]) if len(discharging_partial) > 0 else charging_partial\n",
    "    ax.set_xticks(np.arange(len(all_tests)))\n",
    "    ax.set_xticklabels([t.replace('Charge ', 'C ').replace('Discharge ', 'D ') \n",
    "                        for t in all_tests['Test']], rotation=45, ha='right')\n",
    "    ax.set_ylabel('MAE (%)')\n",
    "    ax.set_title('MAE for Partial Curves', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot RMSE comparison\n",
    "    ax = axes[1]\n",
    "    if len(charging_partial) > 0:\n",
    "        ax.bar(x_charge - 0.2, charging_partial['RMSE'], 0.4, \n",
    "               label='Charging', alpha=0.8, color='green')\n",
    "    if len(discharging_partial) > 0:\n",
    "        ax.bar(x_discharge + 0.2, discharging_partial['RMSE'], 0.4, \n",
    "               label='Discharging', alpha=0.8, color='orange')\n",
    "    \n",
    "    ax.set_xticks(np.arange(len(all_tests)))\n",
    "    ax.set_xticklabels([t.replace('Charge ', 'C ').replace('Discharge ', 'D ') \n",
    "                        for t in all_tests['Test']], rotation=45, ha='right')\n",
    "    ax.set_ylabel('RMSE (%)')\n",
    "    ax.set_title('RMSE for Partial Curves', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -------------------- Mid-SOC Range Predictions Visualization --------------------\n",
    "print(\"\\nGenerating visualizations for mid-SOC ranges...\")\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 12))\n",
    "\n",
    "soc_test_ranges = [\n",
    "    (0, 30, \"Low SOC (0-30%)\", 'blues'),\n",
    "    (30, 60, \"Mid SOC (30-60%)\", 'greens'),\n",
    "    (60, 90, \"High SOC (60-90%)\", 'oranges')\n",
    "]\n",
    "\n",
    "for row_idx, (soc_min, soc_max, range_name, colormap) in enumerate(soc_test_ranges):\n",
    "    # Find sequences that fall primarily in this SOC range\n",
    "    candidates = []\n",
    "    for idx in range(len(X_test)):\n",
    "        mean_soc = np.mean(y_test[idx, :, 0])\n",
    "        if soc_min <= mean_soc <= soc_max:\n",
    "            candidates.append(idx)\n",
    "    \n",
    "    if len(candidates) == 0:\n",
    "        print(f\"No sequences found primarily in {range_name}\")\n",
    "        continue\n",
    "    \n",
    "    # Show one charging and one discharging example from this range\n",
    "    for col_idx, phase_type in enumerate(['C1ch', 'C1dc']):\n",
    "        phase_candidates = [c for c in candidates if phases_test[c] == phase_type]\n",
    "        \n",
    "        if len(phase_candidates) == 0:\n",
    "            ax = axes[row_idx, col_idx]\n",
    "            ax.text(0.5, 0.5, f'No {range_name}\\n{\"Charging\" if phase_type == \"C1ch\" else \"Discharging\"} data',\n",
    "                   ha='center', va='center', fontsize=12)\n",
    "            ax.set_xlim(0, 1)\n",
    "            ax.set_ylim(0, 1)\n",
    "            ax.axis('off')\n",
    "            continue\n",
    "        \n",
    "        # Pick a random sample from this range and phase\n",
    "        idx = np.random.choice(phase_candidates)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            x_sample = torch.tensor(X_test[idx:idx+1], dtype=torch.float32, device=device)\n",
    "            pred = model(x_sample).cpu().numpy()[0, :, 0] * 100\n",
    "        \n",
    "        true = y_test[idx, :, 0]\n",
    "        error = np.abs(true - pred)\n",
    "        mean_error = np.mean(error)\n",
    "        max_error = np.max(error)\n",
    "        phase_label = \"Charging\" if phase_type == 'C1ch' else \"Discharging\"\n",
    "        \n",
    "        ax = axes[row_idx, col_idx]\n",
    "        \n",
    "        # Plot with shaded error region\n",
    "        time_steps = np.arange(len(true))\n",
    "        ax.plot(time_steps, true, 'k-', linewidth=2.5, label='True SOC', alpha=0.8)\n",
    "        ax.plot(time_steps, pred, 'r--', linewidth=2, label='LSTM Prediction', alpha=0.8)\n",
    "        ax.fill_between(time_steps, pred - error, pred + error, alpha=0.2, color='red')\n",
    "        \n",
    "        # Highlight the target SOC range\n",
    "        ax.axhspan(soc_min, soc_max, alpha=0.1, color='green', label=f'{range_name}')\n",
    "        \n",
    "        ax.set_title(f'{range_name} - {phase_label}\\nMAE: {mean_error:.2f}% | Max Error: {max_error:.2f}%', \n",
    "                     fontsize=10, fontweight='bold')\n",
    "        ax.set_xlabel('Time Step', fontsize=9)\n",
    "        ax.set_ylabel('SOC (%)', fontsize=9)\n",
    "        ax.legend(fontsize=8, loc='best')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_ylim(0, 100)\n",
    "\n",
    "plt.suptitle('SOC Estimation in Different SOC Ranges (Charging & Discharging)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -------------------- Sample Predictions Visualization --------------------\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Sample predictions\n",
    "for i in range(4):\n",
    "    idx = np.random.randint(0, len(X_test))\n",
    "    with torch.no_grad():\n",
    "        x_sample = torch.tensor(X_test[idx:idx+1], dtype=torch.float32, device=device)\n",
    "        pred = model(x_sample).cpu().numpy()[0, :, 0] * 100\n",
    "    \n",
    "    true = y_test[idx, :, 0]\n",
    "    error = np.mean(np.abs(true - pred))\n",
    "    phase_label = \"Charging\" if phases_test[idx] == 'C1ch' else \"Discharging\"\n",
    "    \n",
    "    ax = axes[i//2, i%2]\n",
    "    ax.plot(true, 'k-', linewidth=2, label='True SOC')\n",
    "    ax.plot(pred, 'r--', linewidth=2, label='LSTM Prediction')\n",
    "    ax.set_title(f'{phase_label} - Sample {i+1} | MAE: {error:.2f}%', \n",
    "                 fontsize=11, fontweight='bold')\n",
    "    ax.set_xlabel('Time Step')\n",
    "    ax.set_ylabel('SOC (%)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('LSTM SOC Estimation Results (Random Samples)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -------------------- Overall Error Distribution --------------------\n",
    "plt.figure(figsize=(10, 5))\n",
    "errors = (predictions - actuals).flatten()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(errors, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Prediction Error (%)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Error Distribution')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(actuals.flatten(), predictions.flatten(), alpha=0.5, s=1)\n",
    "plt.plot([0, 100], [0, 100], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "plt.xlabel('True SOC (%)')\n",
    "plt.ylabel('Predicted SOC (%)')\n",
    "plt.title('Prediction vs Actual')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65611f2-70d9-4b64-8b11-0836b83f1d1c",
   "metadata": {},
   "source": [
    "GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162af5a7-ac6c-4c62-bcf7-dfa6a0373c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# -------------------- Data Loading --------------------\n",
    "data = scipy.io.loadmat('Oxford_Battery_Degradation_Dataset_1.mat')\n",
    "\n",
    "def soc_from_q(q, phase):\n",
    "    \"\"\"Compute SOC% from charge trace.\"\"\"\n",
    "    q0, q1 = float(q[0]), float(q[-1])\n",
    "    if np.isclose(q1, q0):\n",
    "        return None\n",
    "    qn = (q - q0) / (q1 - q0)\n",
    "    if phase == 'C1ch':\n",
    "        return 100.0 * np.clip(qn, 0, 1)\n",
    "    elif phase == 'C1dc':\n",
    "        return 100.0 * (1.0 - np.clip(qn, 0, 1))\n",
    "    return None\n",
    "\n",
    "def extract_sequences(data, L=128):\n",
    "    \"\"\"Extract V, T, I features and SOC labels.\"\"\"\n",
    "    X_list, y_list, phase_list = [], [], []\n",
    "    \n",
    "    for ci in range(1, 9):\n",
    "        cell = data[f'Cell{ci}']\n",
    "        for cyc_name in sorted(cell.dtype.names, key=lambda s: int(s[3:])):\n",
    "            cyc = cell[cyc_name][0, 0]\n",
    "            for phase in ['C1ch', 'C1dc']:\n",
    "                if phase not in cyc.dtype.names:\n",
    "                    continue\n",
    "                blk = cyc[phase][0, 0]\n",
    "                if not all(k in blk.dtype.names for k in ['t','v','q']):\n",
    "                    continue\n",
    "                \n",
    "                t = blk['t'][0,0].ravel().astype(float)\n",
    "                v = blk['v'][0,0].ravel().astype(float)\n",
    "                q = blk['q'][0,0].ravel().astype(float)\n",
    "                \n",
    "                if t.size < 5:\n",
    "                    continue\n",
    "                \n",
    "                # Temperature (fill missing with forward/backward fill)\n",
    "                if 'T' in blk.dtype.names:\n",
    "                    T = blk['T'][0,0].ravel().astype(float)\n",
    "                else:\n",
    "                    T = np.full_like(t, 25.0)\n",
    "                T = pd.Series(T).ffill().bfill().values\n",
    "                \n",
    "                # Current (use defaults if missing)\n",
    "                if 'i' in blk.dtype.names:\n",
    "                    I = blk['i'][0,0].ravel().astype(float)\n",
    "                else:\n",
    "                    I = np.full_like(t, 0.74 if phase == 'C1ch' else -0.74)\n",
    "                \n",
    "                soc = soc_from_q(q, phase)\n",
    "                if soc is None:\n",
    "                    continue\n",
    "                \n",
    "                # Resample to fixed length L\n",
    "                t_new = np.linspace(t[0], t[-1], L)\n",
    "                v_new = np.interp(t_new, t, v)\n",
    "                T_new = np.interp(t_new, t, T)\n",
    "                I_new = np.interp(t_new, t, I)\n",
    "                y_new = np.interp(t_new, t, soc)\n",
    "                \n",
    "                X = np.stack([v_new, T_new, I_new], axis=-1)  # [L, 3]\n",
    "                y = y_new[:, None]  # [L, 1]\n",
    "                \n",
    "                X_list.append(X)\n",
    "                y_list.append(y)\n",
    "                phase_list.append(phase)  # Track charging vs discharging\n",
    "    \n",
    "    return np.array(X_list), np.array(y_list), np.array(phase_list)\n",
    "\n",
    "# -------------------- Prepare Data --------------------\n",
    "print(\"Loading data...\")\n",
    "X, y, phases = extract_sequences(data, L=128)\n",
    "print(f\"Total sequences: {len(X)}, Shape: {X.shape}\")\n",
    "\n",
    "# Train/test split (80/20)\n",
    "n_train = int(0.8 * len(X))\n",
    "X_train, X_test = X[:n_train], X[n_train:]\n",
    "y_train, y_test = y[:n_train], y[n_train:]\n",
    "phases_test = phases[n_train:]\n",
    "\n",
    "# Normalize features\n",
    "mu = X_train.reshape(-1, X_train.shape[-1]).mean(axis=0)\n",
    "sd = X_train.reshape(-1, X_train.shape[-1]).std(axis=0) + 1e-8\n",
    "X_train = (X_train - mu) / sd\n",
    "X_test = (X_test - mu) / sd\n",
    "\n",
    "# Normalize labels to [0, 1]\n",
    "y_train_norm = y_train / 100.0\n",
    "y_test_norm = y_test / 100.0\n",
    "\n",
    "print(f\"Train: {len(X_train)} | Test: {len(X_test)}\")\n",
    "\n",
    "# -------------------- DataLoaders --------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\\n\")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                  torch.tensor(y_train_norm, dtype=torch.float32)),\n",
    "    batch_size=32, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    TensorDataset(torch.tensor(X_test, dtype=torch.float32),\n",
    "                  torch.tensor(y_test_norm, dtype=torch.float32)),\n",
    "    batch_size=32, shuffle=False)\n",
    "\n",
    "# -------------------- GRU Model --------------------\n",
    "class GRU_SOC(nn.Module):\n",
    "    def __init__(self, input_dim=3, hidden=128, layers=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden, num_layers=layers, \n",
    "                         batch_first=True, dropout=dropout if layers > 1 else 0)\n",
    "        self.fc = nn.Linear(hidden, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch, seq_len, input_dim]\n",
    "        out, _ = self.gru(x)  # out shape: [batch, seq_len, hidden]\n",
    "        return self.fc(out)   # shape: [batch, seq_len, 1]\n",
    "\n",
    "model = GRU_SOC(input_dim=3, hidden=128, layers=2, dropout=0.2).to(device)\n",
    "print(f\"Model: GRU with {sum(p.numel() for p in model.parameters()):,} parameters\\n\")\n",
    "\n",
    "# -------------------- Training --------------------\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "epochs = 100\n",
    "best_loss = float('inf')\n",
    "\n",
    "print(\"Training GRU model...\")\n",
    "for epoch in range(epochs):\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb)\n",
    "        loss = loss_fn(pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * xb.size(0)\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    \n",
    "    # Validate\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            test_loss += loss_fn(model(xb), yb).item() * xb.size(0)\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    # Save best model\n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        torch.save(model.state_dict(), 'best_gru.pt')\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1:03d} | Train Loss: {train_loss:.6f} | Test Loss: {test_loss:.6f}\")\n",
    "\n",
    "print(f\"\\nBest Test Loss: {best_loss:.6f}\")\n",
    "\n",
    "# -------------------- Validation --------------------\n",
    "model.load_state_dict(torch.load('best_gru.pt'))\n",
    "model.eval()\n",
    "\n",
    "# Get predictions\n",
    "predictions, actuals = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        pred = model(xb).cpu().numpy()\n",
    "        predictions.append(pred)\n",
    "        actuals.append(yb.numpy())\n",
    "\n",
    "predictions = np.concatenate(predictions) * 100  # Convert back to %\n",
    "actuals = np.concatenate(actuals) * 100\n",
    "\n",
    "# Calculate overall metrics\n",
    "mae = np.mean(np.abs(predictions - actuals))\n",
    "rmse = np.sqrt(np.mean((predictions - actuals)**2))\n",
    "max_error = np.max(np.abs(predictions - actuals))\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Overall Validation Metrics (GRU):\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"MAE:        {mae:.4f}%\")\n",
    "print(f\"RMSE:       {rmse:.4f}%\")\n",
    "print(f\"Max Error:  {max_error:.4f}%\")\n",
    "\n",
    "# -------------------- SOC Range Analysis --------------------\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SOC Range Analysis\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Define SOC ranges to test\n",
    "soc_ranges = [\n",
    "    (0, 30, \"Low SOC (0-30%)\"),\n",
    "    (30, 60, \"Mid SOC (30-60%)\"),\n",
    "    (60, 90, \"High SOC (60-90%)\"),\n",
    "    (0, 100, \"Full Range (0-100%)\")\n",
    "]\n",
    "\n",
    "range_metrics = []\n",
    "\n",
    "for soc_min, soc_max, range_name in soc_ranges:\n",
    "    # Filter predictions and actuals for this SOC range\n",
    "    mask = (actuals >= soc_min) & (actuals <= soc_max)\n",
    "    \n",
    "    if np.sum(mask) == 0:\n",
    "        print(f\"\\n{range_name}: No data points in this range\")\n",
    "        continue\n",
    "    \n",
    "    range_preds = predictions[mask]\n",
    "    range_actuals = actuals[mask]\n",
    "    \n",
    "    # Calculate metrics for this range\n",
    "    range_mae = np.mean(np.abs(range_preds - range_actuals))\n",
    "    range_rmse = np.sqrt(np.mean((range_preds - range_actuals)**2))\n",
    "    range_max_error = np.max(np.abs(range_preds - range_actuals))\n",
    "    n_points = np.sum(mask)\n",
    "    \n",
    "    range_metrics.append({\n",
    "        'Range': range_name,\n",
    "        'MAE': range_mae,\n",
    "        'RMSE': range_rmse,\n",
    "        'Max Error': range_max_error,\n",
    "        'N Points': n_points\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{range_name}:\")\n",
    "    print(f\"  Points:     {n_points:,}\")\n",
    "    print(f\"  MAE:        {range_mae:.4f}%\")\n",
    "    print(f\"  RMSE:       {range_rmse:.4f}%\")\n",
    "    print(f\"  Max Error:  {range_max_error:.4f}%\")\n",
    "\n",
    "# Create DataFrame for easier visualization\n",
    "metrics_df = pd.DataFrame(range_metrics)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Summary Table:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(metrics_df.to_string(index=False))\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# -------------------- Phase-specific Analysis --------------------\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Charging vs Discharging Analysis\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "phase_metrics = []\n",
    "\n",
    "for phase_type in ['C1ch', 'C1dc']:\n",
    "    phase_name = \"Charging\" if phase_type == 'C1ch' else \"Discharging\"\n",
    "    \n",
    "    # Get indices for this phase\n",
    "    phase_mask = phases_test == phase_type\n",
    "    \n",
    "    if np.sum(phase_mask) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Get predictions for this phase\n",
    "    phase_preds = predictions[phase_mask]\n",
    "    phase_actuals = actuals[phase_mask]\n",
    "    \n",
    "    # Overall phase metrics\n",
    "    phase_mae = np.mean(np.abs(phase_preds - phase_actuals))\n",
    "    phase_rmse = np.sqrt(np.mean((phase_preds - phase_actuals)**2))\n",
    "    \n",
    "    print(f\"\\n{phase_name}:\")\n",
    "    print(f\"  Sequences:  {np.sum(phase_mask)}\")\n",
    "    print(f\"  MAE:        {phase_mae:.4f}%\")\n",
    "    print(f\"  RMSE:       {phase_rmse:.4f}%\")\n",
    "    \n",
    "    # Break down by SOC ranges\n",
    "    for soc_min, soc_max, range_name in soc_ranges[:3]:  # Only low, mid, high\n",
    "        range_mask = (phase_actuals >= soc_min) & (phase_actuals <= soc_max)\n",
    "        \n",
    "        if np.sum(range_mask) > 0:\n",
    "            sub_preds = phase_preds[range_mask]\n",
    "            sub_actuals = phase_actuals[range_mask]\n",
    "            sub_mae = np.mean(np.abs(sub_preds - sub_actuals))\n",
    "            sub_rmse = np.sqrt(np.mean((sub_preds - sub_actuals)**2))\n",
    "            \n",
    "            print(f\"    {range_name}:\")\n",
    "            print(f\"      Points: {np.sum(range_mask):,} | MAE: {sub_mae:.4f}% | RMSE: {sub_rmse:.4f}%\")\n",
    "            \n",
    "            phase_metrics.append({\n",
    "                'Phase': phase_name,\n",
    "                'Range': range_name,\n",
    "                'MAE': sub_mae,\n",
    "                'RMSE': sub_rmse,\n",
    "                'N Points': np.sum(range_mask)\n",
    "            })\n",
    "\n",
    "# -------------------- Partial Curve Testing --------------------\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Testing on Partial Charge/Discharge Curves\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "def create_partial_curve(X_seq, y_seq, soc_start, soc_end):\n",
    "    \"\"\"\n",
    "    Extract a partial curve from a full charge/discharge sequence.\n",
    "    \n",
    "    Args:\n",
    "        X_seq: Input features [L, 3]\n",
    "        y_seq: SOC labels [L, 1]\n",
    "        soc_start: Starting SOC%\n",
    "        soc_end: Ending SOC%\n",
    "    \n",
    "    Returns:\n",
    "        Partial X, y sequences\n",
    "    \"\"\"\n",
    "    soc_values = y_seq[:, 0]\n",
    "    \n",
    "    # Find indices where SOC is within the range\n",
    "    if soc_start < soc_end:  # Charging direction\n",
    "        mask = (soc_values >= soc_start) & (soc_values <= soc_end)\n",
    "    else:  # Discharging direction\n",
    "        mask = (soc_values <= soc_start) & (soc_values >= soc_end)\n",
    "    \n",
    "    if np.sum(mask) < 10:  # Need at least 10 points\n",
    "        return None, None\n",
    "    \n",
    "    indices = np.where(mask)[0]\n",
    "    start_idx, end_idx = indices[0], indices[-1] + 1\n",
    "    \n",
    "    return X_seq[start_idx:end_idx], y_seq[start_idx:end_idx]\n",
    "\n",
    "# Define partial curve test cases\n",
    "partial_curve_tests = [\n",
    "    # Charging scenarios\n",
    "    (0, 30, 'C1ch', 'Charge 0-30%'),\n",
    "    (30, 60, 'C1ch', 'Charge 30-60%'),\n",
    "    (60, 90, 'C1ch', 'Charge 60-90%'),\n",
    "    (20, 80, 'C1ch', 'Charge 20-80%'),\n",
    "    \n",
    "    # Discharging scenarios\n",
    "    (100, 70, 'C1dc', 'Discharge 100-70%'),\n",
    "    (70, 40, 'C1dc', 'Discharge 70-40%'),\n",
    "    (40, 10, 'C1dc', 'Discharge 40-10%'),\n",
    "    (80, 20, 'C1dc', 'Discharge 80-20%'),\n",
    "]\n",
    "\n",
    "partial_results = []\n",
    "\n",
    "for soc_start, soc_end, phase_type, test_name in partial_curve_tests:\n",
    "    # Find test sequences of the right phase\n",
    "    phase_mask = phases_test == phase_type\n",
    "    phase_indices = np.where(phase_mask)[0]\n",
    "    \n",
    "    if len(phase_indices) == 0:\n",
    "        print(f\"\\n{test_name}: No {phase_type} sequences available\")\n",
    "        continue\n",
    "    \n",
    "    # Process multiple sequences for this test case\n",
    "    test_preds, test_actuals = [], []\n",
    "    valid_sequences = 0\n",
    "    \n",
    "    for idx in phase_indices[:50]:  # Test on up to 50 sequences\n",
    "        X_seq = X_test[idx]\n",
    "        y_seq = y_test[idx]\n",
    "        \n",
    "        # Create partial curve\n",
    "        X_partial, y_partial = create_partial_curve(X_seq, y_seq, soc_start, soc_end)\n",
    "        \n",
    "        if X_partial is None:\n",
    "            continue\n",
    "        \n",
    "        valid_sequences += 1\n",
    "        \n",
    "        # Get prediction for partial curve\n",
    "        with torch.no_grad():\n",
    "            x_input = torch.tensor(X_partial[np.newaxis, :, :], dtype=torch.float32, device=device)\n",
    "            pred = model(x_input).cpu().numpy()[0, :, 0] * 100\n",
    "        \n",
    "        true = y_partial[:, 0]\n",
    "        \n",
    "        test_preds.append(pred)\n",
    "        test_actuals.append(true)\n",
    "    \n",
    "    if valid_sequences == 0:\n",
    "        print(f\"\\n{test_name}: No valid partial curves found in range\")\n",
    "        continue\n",
    "    \n",
    "    # Concatenate all predictions\n",
    "    all_preds = np.concatenate(test_preds)\n",
    "    all_actuals = np.concatenate(test_actuals)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = np.mean(np.abs(all_preds - all_actuals))\n",
    "    rmse = np.sqrt(np.mean((all_preds - all_actuals)**2))\n",
    "    max_error = np.max(np.abs(all_preds - all_actuals))\n",
    "    \n",
    "    partial_results.append({\n",
    "        'Test': test_name,\n",
    "        'Phase': phase_type,\n",
    "        'SOC Range': f\"{soc_start}-{soc_end}%\",\n",
    "        'Sequences': valid_sequences,\n",
    "        'Points': len(all_preds),\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'Max Error': max_error\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{test_name}:\")\n",
    "    print(f\"  Valid Sequences: {valid_sequences}\")\n",
    "    print(f\"  Total Points:    {len(all_preds):,}\")\n",
    "    print(f\"  MAE:             {mae:.4f}%\")\n",
    "    print(f\"  RMSE:            {rmse:.4f}%\")\n",
    "    print(f\"  Max Error:       {max_error:.4f}%\")\n",
    "\n",
    "# Create summary table\n",
    "if len(partial_results) > 0:\n",
    "    partial_df = pd.DataFrame(partial_results)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Partial Curve Testing Summary:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(partial_df.to_string(index=False))\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "# -------------------- Partial Curve Visualization --------------------\n",
    "print(\"\\nGenerating partial curve visualizations...\")\n",
    "\n",
    "fig, axes = plt.subplots(4, 2, figsize=(14, 16))\n",
    "\n",
    "# Select interesting partial curve examples\n",
    "visualization_tests = [\n",
    "    (0, 30, 'C1ch', 'Charge 0-30%', 0, 0),\n",
    "    (30, 60, 'C1ch', 'Charge 30-60%', 0, 1),\n",
    "    (60, 90, 'C1ch', 'Charge 60-90%', 1, 0),\n",
    "    (20, 80, 'C1ch', 'Charge 20-80%', 1, 1),\n",
    "    (100, 70, 'C1dc', 'Discharge 100-70%', 2, 0),\n",
    "    (70, 40, 'C1dc', 'Discharge 70-40%', 2, 1),\n",
    "    (40, 10, 'C1dc', 'Discharge 40-10%', 3, 0),\n",
    "    (80, 20, 'C1dc', 'Discharge 80-20%', 3, 1),\n",
    "]\n",
    "\n",
    "for soc_start, soc_end, phase_type, test_name, row, col in visualization_tests:\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    # Find a suitable test sequence\n",
    "    phase_mask = phases_test == phase_type\n",
    "    phase_indices = np.where(phase_mask)[0]\n",
    "    \n",
    "    found = False\n",
    "    for idx in phase_indices[:100]:  # Search through sequences\n",
    "        X_seq = X_test[idx]\n",
    "        y_seq = y_test[idx]\n",
    "        \n",
    "        # Create partial curve\n",
    "        X_partial, y_partial = create_partial_curve(X_seq, y_seq, soc_start, soc_end)\n",
    "        \n",
    "        if X_partial is None or len(X_partial) < 10:\n",
    "            continue\n",
    "        \n",
    "        # Get prediction\n",
    "        with torch.no_grad():\n",
    "            x_input = torch.tensor(X_partial[np.newaxis, :, :], dtype=torch.float32, device=device)\n",
    "            pred = model(x_input).cpu().numpy()[0, :, 0] * 100\n",
    "        \n",
    "        true = y_partial[:, 0]\n",
    "        error = np.abs(true - pred)\n",
    "        mae = np.mean(error)\n",
    "        max_error = np.max(error)\n",
    "        \n",
    "        # Plot\n",
    "        time_steps = np.arange(len(true))\n",
    "        ax.plot(time_steps, true, 'b-', linewidth=2.5, label='True SOC', alpha=0.8)\n",
    "        ax.plot(time_steps, pred, 'r--', linewidth=2, label='GRU Prediction', alpha=0.8)\n",
    "        ax.fill_between(time_steps, true, pred, alpha=0.2, color='orange')\n",
    "        \n",
    "        # Add horizontal lines for SOC range\n",
    "        ax.axhline(soc_start, color='green', linestyle=':', linewidth=1.5, alpha=0.7, label=f'Start: {soc_start}%')\n",
    "        if phase_type == 'C1ch':\n",
    "            ax.axhline(soc_end, color='red', linestyle=':', linewidth=1.5, alpha=0.7, label=f'End: {soc_end}%')\n",
    "        else:\n",
    "            ax.axhline(soc_end, color='red', linestyle=':', linewidth=1.5, alpha=0.7, label=f'End: {soc_end}%')\n",
    "        \n",
    "        ax.set_title(f'{test_name}\\nMAE: {mae:.2f}% | Max Error: {max_error:.2f}%', \n",
    "                     fontsize=10, fontweight='bold')\n",
    "        ax.set_xlabel('Time Step', fontsize=9)\n",
    "        ax.set_ylabel('SOC (%)', fontsize=9)\n",
    "        ax.legend(fontsize=7, loc='best')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_ylim(max(0, min(soc_start, soc_end) - 10), \n",
    "                    min(100, max(soc_start, soc_end) + 10))\n",
    "        \n",
    "        found = True\n",
    "        break\n",
    "    \n",
    "    if not found:\n",
    "        ax.text(0.5, 0.5, f'No valid\\n{test_name}\\ndata found',\n",
    "               ha='center', va='center', fontsize=10, transform=ax.transAxes)\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "plt.suptitle('GRU Performance on Partial Charge/Discharge Curves', \n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -------------------- Comparison: Full vs Partial Curves --------------------\n",
    "if len(partial_results) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Separate charging and discharging\n",
    "    charging_partial = partial_df[partial_df['Phase'] == 'C1ch']\n",
    "    discharging_partial = partial_df[partial_df['Phase'] == 'C1dc']\n",
    "    \n",
    "    # Plot MAE comparison\n",
    "    ax = axes[0]\n",
    "    if len(charging_partial) > 0:\n",
    "        x_charge = np.arange(len(charging_partial))\n",
    "        ax.bar(x_charge - 0.2, charging_partial['MAE'], 0.4, \n",
    "               label='Charging', alpha=0.8, color='green')\n",
    "    if len(discharging_partial) > 0:\n",
    "        x_discharge = np.arange(len(discharging_partial))\n",
    "        ax.bar(x_discharge + 0.2, discharging_partial['MAE'], 0.4, \n",
    "               label='Discharging', alpha=0.8, color='orange')\n",
    "    \n",
    "    all_tests = pd.concat([charging_partial, discharging_partial]) if len(discharging_partial) > 0 else charging_partial\n",
    "    ax.set_xticks(np.arange(len(all_tests)))\n",
    "    ax.set_xticklabels([t.replace('Charge ', 'C ').replace('Discharge ', 'D ') \n",
    "                        for t in all_tests['Test']], rotation=45, ha='right')\n",
    "    ax.set_ylabel('MAE (%)')\n",
    "    ax.set_title('MAE for Partial Curves (GRU)', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot RMSE comparison\n",
    "    ax = axes[1]\n",
    "    if len(charging_partial) > 0:\n",
    "        ax.bar(x_charge - 0.2, charging_partial['RMSE'], 0.4, \n",
    "               label='Charging', alpha=0.8, color='green')\n",
    "    if len(discharging_partial) > 0:\n",
    "        ax.bar(x_discharge + 0.2, discharging_partial['RMSE'], 0.4, \n",
    "               label='Discharging', alpha=0.8, color='orange')\n",
    "    \n",
    "    ax.set_xticks(np.arange(len(all_tests)))\n",
    "    ax.set_xticklabels([t.replace('Charge ', 'C ').replace('Discharge ', 'D ') \n",
    "                        for t in all_tests['Test']], rotation=45, ha='right')\n",
    "    ax.set_ylabel('RMSE (%)')\n",
    "    ax.set_title('RMSE for Partial Curves (GRU)', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -------------------- Range-specific Visualization --------------------\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# Plot metrics comparison\n",
    "ax = axes[0, 0]\n",
    "x_pos = np.arange(len(range_metrics))\n",
    "ax.bar(x_pos, [m['MAE'] for m in range_metrics], alpha=0.7, color='steelblue')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([m['Range'].split('(')[0].strip() for m in range_metrics], rotation=45, ha='right')\n",
    "ax.set_ylabel('MAE (%)')\n",
    "ax.set_title('MAE by SOC Range (GRU)', fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "ax = axes[0, 1]\n",
    "ax.bar(x_pos, [m['RMSE'] for m in range_metrics], alpha=0.7, color='coral')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([m['Range'].split('(')[0].strip() for m in range_metrics], rotation=45, ha='right')\n",
    "ax.set_ylabel('RMSE (%)')\n",
    "ax.set_title('RMSE by SOC Range (GRU)', fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "ax = axes[0, 2]\n",
    "ax.bar(x_pos, [m['Max Error'] for m in range_metrics], alpha=0.7, color='lightcoral')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([m['Range'].split('(')[0].strip() for m in range_metrics], rotation=45, ha='right')\n",
    "ax.set_ylabel('Max Error (%)')\n",
    "ax.set_title('Max Error by SOC Range (GRU)', fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot error distribution by range\n",
    "for idx, (soc_min, soc_max, range_name) in enumerate(soc_ranges[:3]):\n",
    "    ax = axes[1, idx]\n",
    "    mask = (actuals >= soc_min) & (actuals <= soc_max)\n",
    "    \n",
    "    if np.sum(mask) > 0:\n",
    "        range_errors = (predictions[mask] - actuals[mask]).flatten()\n",
    "        ax.hist(range_errors, bins=30, edgecolor='black', alpha=0.7, color='teal')\n",
    "        ax.axvline(0, color='red', linestyle='--', linewidth=2, label='Zero Error')\n",
    "        ax.set_xlabel('Error (%)')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.set_title(f'{range_name}\\nMean Error: {np.mean(range_errors):.3f}%', fontweight='bold')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('GRU SOC Range Analysis', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -------------------- Phase-specific Visualization --------------------\n",
    "if len(phase_metrics) > 0:\n",
    "    phase_df = pd.DataFrame(phase_metrics)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Grouped bar chart for MAE\n",
    "    ax = axes[0]\n",
    "    ranges_unique = phase_df['Range'].unique()\n",
    "    x = np.arange(len(ranges_unique))\n",
    "    width = 0.35\n",
    "    \n",
    "    charging_data = phase_df[phase_df['Phase'] == 'Charging']\n",
    "    discharging_data = phase_df[phase_df['Phase'] == 'Discharging']\n",
    "    \n",
    "    charge_mae = [charging_data[charging_data['Range'] == r]['MAE'].values[0] \n",
    "                  if len(charging_data[charging_data['Range'] == r]) > 0 else 0 \n",
    "                  for r in ranges_unique]\n",
    "    discharge_mae = [discharging_data[discharging_data['Range'] == r]['MAE'].values[0] \n",
    "                     if len(discharging_data[discharging_data['Range'] == r]) > 0 else 0 \n",
    "                     for r in ranges_unique]\n",
    "    \n",
    "    ax.bar(x - width/2, charge_mae, width, label='Charging', alpha=0.8, color='green')\n",
    "    ax.bar(x + width/2, discharge_mae, width, label='Discharging', alpha=0.8, color='orange')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([r.split('(')[0].strip() for r in ranges_unique], rotation=45, ha='right')\n",
    "    ax.set_ylabel('MAE (%)')\n",
    "    ax.set_title('MAE: Charging vs Discharging by SOC Range (GRU)', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Grouped bar chart for RMSE\n",
    "    ax = axes[1]\n",
    "    charge_rmse = [charging_data[charging_data['Range'] == r]['RMSE'].values[0] \n",
    "                   if len(charging_data[charging_data['Range'] == r]) > 0 else 0 \n",
    "                   for r in ranges_unique]\n",
    "    discharge_rmse = [discharging_data[discharging_data['Range'] == r]['RMSE'].values[0] \n",
    "                      if len(discharging_data[discharging_data['Range'] == r]) > 0 else 0 \n",
    "                      for r in ranges_unique]\n",
    "    \n",
    "    ax.bar(x - width/2, charge_rmse, width, label='Charging', alpha=0.8, color='green')\n",
    "    ax.bar(x + width/2, discharge_rmse, width, label='Discharging', alpha=0.8, color='orange')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([r.split('(')[0].strip() for r in ranges_unique], rotation=45, ha='right')\n",
    "    ax.set_ylabel('RMSE (%)')\n",
    "    ax.set_title('RMSE: Charging vs Discharging by SOC Range (GRU)', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# -------------------- Sample Predictions Visualization --------------------\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# Sample predictions\n",
    "for i in range(4):\n",
    "    idx = np.random.randint(0, len(X_test))\n",
    "    with torch.no_grad():\n",
    "        x_sample = torch.tensor(X_test[idx:idx+1], dtype=torch.float32, device=device)\n",
    "        pred = model(x_sample).cpu().numpy()[0, :, 0] * 100\n",
    "    \n",
    "    true = y_test[idx, :, 0]\n",
    "    error = np.mean(np.abs(true - pred))\n",
    "    phase_label = \"Charging\" if phases_test[idx] == 'C1ch' else \"Discharging\"\n",
    "    \n",
    "    ax = axes[i//2, i%2]\n",
    "    ax.plot(true, 'k-', linewidth=2, label='True SOC')\n",
    "    ax.plot(pred, 'r--', linewidth=2, label='GRU Prediction')\n",
    "    ax.set_title(f'{phase_label} - Sample {i+1} | MAE: {error:.2f}%', \n",
    "                 fontsize=11, fontweight='bold')\n",
    "    ax.set_xlabel('Time Step')\n",
    "    ax.set_ylabel('SOC (%)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('GRU SOC Estimation Results (Random Samples)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -------------------- Overall Error Distribution --------------------\n",
    "plt.figure(figsize=(10, 5))\n",
    "errors = (predictions - actuals).flatten()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(errors, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Prediction Error (%)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Error Distribution (GRU)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(actuals.flatten(), predictions.flatten(), alpha=0.5, s=1)\n",
    "plt.plot([0, 100], [0, 100], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "plt.xlabel('True SOC (%)')\n",
    "plt.ylabel('Predicted SOC (%)')\n",
    "plt.title('Prediction vs Actual (GRU)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c197f64-cb70-4920-9331-06f61aa5ec4e",
   "metadata": {},
   "source": [
    "GRU-PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9dd278-e0d7-4142-812c-9a91ad2407b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# -------------------- Data Loading --------------------\n",
    "data = scipy.io.loadmat('Oxford_Battery_Degradation_Dataset_1.mat')\n",
    "\n",
    "def soc_from_q(q, phase):\n",
    "    \"\"\"Compute SOC% from charge trace.\"\"\"\n",
    "    q0, q1 = float(q[0]), float(q[-1])\n",
    "    if np.isclose(q1, q0):\n",
    "        return None\n",
    "    qn = (q - q0) / (q1 - q0)\n",
    "    if phase == 'C1ch':\n",
    "        return 100.0 * np.clip(qn, 0, 1)\n",
    "    elif phase == 'C1dc':\n",
    "        return 100.0 * (1.0 - np.clip(qn, 0, 1))\n",
    "    return None\n",
    "\n",
    "def extract_sequences_with_physics(data, L=128):\n",
    "    \"\"\"Extract V, T, I features and SOC labels with physics-based features.\"\"\"\n",
    "    X_list, y_list, phase_list = [], [], []\n",
    "    \n",
    "    for ci in range(1, 9):\n",
    "        cell = data[f'Cell{ci}']\n",
    "        for cyc_name in sorted(cell.dtype.names, key=lambda s: int(s[3:])):\n",
    "            cyc = cell[cyc_name][0, 0]\n",
    "            for phase in ['C1ch', 'C1dc']:\n",
    "                if phase not in cyc.dtype.names:\n",
    "                    continue\n",
    "                blk = cyc[phase][0, 0]\n",
    "                if not all(k in blk.dtype.names for k in ['t','v','q']):\n",
    "                    continue\n",
    "                \n",
    "                t = blk['t'][0,0].ravel().astype(float)\n",
    "                v = blk['v'][0,0].ravel().astype(float)\n",
    "                q = blk['q'][0,0].ravel().astype(float)\n",
    "                \n",
    "                if t.size < 5:\n",
    "                    continue\n",
    "                \n",
    "                # Temperature (fill missing with forward/backward fill)\n",
    "                if 'T' in blk.dtype.names:\n",
    "                    T = blk['T'][0,0].ravel().astype(float)\n",
    "                else:\n",
    "                    T = np.full_like(t, 25.0)\n",
    "                T = pd.Series(T).ffill().bfill().values\n",
    "                \n",
    "                # Current (use defaults if missing)\n",
    "                if 'i' in blk.dtype.names:\n",
    "                    I = blk['i'][0,0].ravel().astype(float)\n",
    "                else:\n",
    "                    I = np.full_like(t, 0.74 if phase == 'C1ch' else -0.74)\n",
    "                \n",
    "                soc = soc_from_q(q, phase)\n",
    "                if soc is None:\n",
    "                    continue\n",
    "                \n",
    "                # Resample to fixed length L\n",
    "                t_new = np.linspace(t[0], t[-1], L)\n",
    "                v_new = np.interp(t_new, t, v)\n",
    "                T_new = np.interp(t_new, t, T)\n",
    "                I_new = np.interp(t_new, t, I)\n",
    "                q_new = np.interp(t_new, t, q)\n",
    "                y_new = np.interp(t_new, t, soc)\n",
    "                \n",
    "                # ============ PHYSICS-BASED FEATURES ============\n",
    "                \n",
    "                # 1. Voltage derivative (dV/dt) - rate of voltage change\n",
    "                dv_dt = np.gradient(v_new, t_new)\n",
    "                \n",
    "                # 2. Current integral (Coulomb counting proxy)\n",
    "                # Cumulative charge from start\n",
    "                dt = np.diff(t_new, prepend=t_new[0])\n",
    "                cumulative_q = np.cumsum(I_new * dt)\n",
    "                \n",
    "                # 3. Temperature derivative (dT/dt) - thermal dynamics\n",
    "                dT_dt = np.gradient(T_new, t_new)\n",
    "                \n",
    "                # 4. Voltage per current (approximate resistance)\n",
    "                # R  V/I (avoid division by zero)\n",
    "                resistance = np.where(np.abs(I_new) > 0.01, \n",
    "                                     (v_new - np.mean(v_new)) / (I_new + 1e-6), \n",
    "                                     0.0)\n",
    "                \n",
    "                # 5. Power (P = V * I)\n",
    "                power = v_new * I_new\n",
    "                \n",
    "                # 6. Energy integral (P dt)\n",
    "                energy = np.cumsum(power * dt)\n",
    "                \n",
    "                # 7. Charge direction indicator\n",
    "                charge_indicator = np.sign(I_new)  # +1 for charging, -1 for discharging\n",
    "                \n",
    "                # 8. Normalized capacity (charge throughput)\n",
    "                # This is similar to SOC but computed from current integration\n",
    "                if phase == 'C1ch':\n",
    "                    q_norm = (cumulative_q - cumulative_q[0]) / (cumulative_q[-1] - cumulative_q[0] + 1e-6)\n",
    "                else:\n",
    "                    q_norm = 1.0 - (cumulative_q - cumulative_q[0]) / (cumulative_q[-1] - cumulative_q[0] + 1e-6)\n",
    "                q_norm = np.clip(q_norm, 0, 1)\n",
    "                \n",
    "                # 9. Voltage-SOC correlation feature (empirical OCV)\n",
    "                # Approximate open circuit voltage based on typical Li-ion OCV curve\n",
    "                # OCV  3.0 + 1.2 * SOC_normalized (simplified linear model)\n",
    "                estimated_ocv = 3.0 + 1.2 * (q_norm)\n",
    "                ocv_deviation = v_new - estimated_ocv\n",
    "                \n",
    "                # 10. Temperature-normalized voltage\n",
    "                # Voltage typically changes ~0.5mV/C\n",
    "                T_ref = 25.0\n",
    "                v_temp_compensated = v_new - 0.0005 * (T_new - T_ref)\n",
    "                \n",
    "                # Stack all features: [L, 13]\n",
    "                # Original: V, T, I (3)\n",
    "                # Physics: dV/dt, cumulative_q, dT/dt, resistance, power, energy,\n",
    "                #          charge_indicator, q_norm, ocv_deviation, v_temp_compensated (10)\n",
    "                X = np.stack([\n",
    "                    v_new,                  # 0: Voltage\n",
    "                    T_new,                  # 1: Temperature\n",
    "                    I_new,                  # 2: Current\n",
    "                    dv_dt,                  # 3: Voltage derivative\n",
    "                    cumulative_q,           # 4: Cumulative charge\n",
    "                    dT_dt,                  # 5: Temperature derivative\n",
    "                    resistance,             # 6: Approximate resistance\n",
    "                    power,                  # 7: Power\n",
    "                    energy,                 # 8: Cumulative energy\n",
    "                    charge_indicator,       # 9: Charge direction\n",
    "                    q_norm,                 # 10: Normalized capacity\n",
    "                    ocv_deviation,          # 11: OCV deviation\n",
    "                    v_temp_compensated      # 12: Temperature-compensated voltage\n",
    "                ], axis=-1)\n",
    "                \n",
    "                y = y_new[:, None]  # [L, 1]\n",
    "                \n",
    "                X_list.append(X)\n",
    "                y_list.append(y)\n",
    "                phase_list.append(phase)\n",
    "    \n",
    "    return np.array(X_list), np.array(y_list), np.array(phase_list)\n",
    "\n",
    "# -------------------- Prepare Data --------------------\n",
    "print(\"Loading data with physics-based features...\")\n",
    "X, y, phases = extract_sequences_with_physics(data, L=128)\n",
    "print(f\"Total sequences: {len(X)}, Shape: {X.shape}\")\n",
    "print(f\"Feature dimensions: {X.shape[-1]} (13 physics-informed features)\")\n",
    "\n",
    "# Train/test split (80/20)\n",
    "n_train = int(0.8 * len(X))\n",
    "X_train, X_test = X[:n_train], X[n_train:]\n",
    "y_train, y_test = y[:n_train], y[n_train:]\n",
    "phases_test = phases[n_train:]\n",
    "\n",
    "# Normalize features\n",
    "mu = X_train.reshape(-1, X_train.shape[-1]).mean(axis=0)\n",
    "sd = X_train.reshape(-1, X_train.shape[-1]).std(axis=0) + 1e-8\n",
    "X_train = (X_train - mu) / sd\n",
    "X_test = (X_test - mu) / sd\n",
    "\n",
    "# Normalize labels to [0, 1]\n",
    "y_train_norm = y_train / 100.0\n",
    "y_test_norm = y_test / 100.0\n",
    "\n",
    "print(f\"Train: {len(X_train)} | Test: {len(X_test)}\")\n",
    "\n",
    "# -------------------- DataLoaders --------------------\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\\n\")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                  torch.tensor(y_train_norm, dtype=torch.float32)),\n",
    "    batch_size=32, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    TensorDataset(torch.tensor(X_test, dtype=torch.float32),\n",
    "                  torch.tensor(y_test_norm, dtype=torch.float32)),\n",
    "    batch_size=32, shuffle=False)\n",
    "\n",
    "# -------------------- Physics-Informed GRU Model --------------------\n",
    "class PhysicsInformedGRU(nn.Module):\n",
    "    \"\"\"\n",
    "    Physics-Informed GRU for SOC estimation with:\n",
    "    1. Physics-based features\n",
    "    2. Physics-constrained loss\n",
    "    3. Monotonicity enforcement (optional)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=13, hidden=128, layers=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Feature extraction layer for physics features\n",
    "        self.feature_encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        \n",
    "        # GRU layers\n",
    "        self.gru = nn.GRU(64, hidden, num_layers=layers, \n",
    "                         batch_first=True, dropout=dropout if layers > 1 else 0)\n",
    "        \n",
    "        # Output layers with residual connection\n",
    "        self.fc1 = nn.Linear(hidden, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        \n",
    "        # Physics-based attention (weight different features)\n",
    "        self.feature_attention = nn.Linear(input_dim, input_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass with physics-informed processing\n",
    "        \n",
    "        Args:\n",
    "            x: [batch, seq_len, input_dim]\n",
    "        \n",
    "        Returns:\n",
    "            soc: [batch, seq_len, 1]\n",
    "        \"\"\"\n",
    "        # Apply attention to input features\n",
    "        attention_weights = torch.sigmoid(self.feature_attention(x))\n",
    "        x_attended = x * attention_weights\n",
    "        \n",
    "        # Encode features\n",
    "        x_encoded = self.feature_encoder(x_attended)\n",
    "        \n",
    "        # GRU processing\n",
    "        gru_out, _ = self.gru(x_encoded)\n",
    "        \n",
    "        # Output layers\n",
    "        out = self.fc1(gru_out)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "        soc = self.fc2(out)\n",
    "        \n",
    "        return soc\n",
    "\n",
    "class PhysicsInformedLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Custom loss function incorporating physics constraints\n",
    "    \"\"\"\n",
    "    def __init__(self, lambda_mse=1.0, lambda_monotonic=0.1, lambda_coulomb=0.05):\n",
    "        super().__init__()\n",
    "        self.lambda_mse = lambda_mse\n",
    "        self.lambda_monotonic = lambda_monotonic\n",
    "        self.lambda_coulomb = lambda_coulomb\n",
    "        self.mse = nn.MSELoss()\n",
    "    \n",
    "    def forward(self, pred, target, features):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            pred: [batch, seq_len, 1] - predicted SOC\n",
    "            target: [batch, seq_len, 1] - true SOC\n",
    "            features: [batch, seq_len, input_dim] - input features\n",
    "        \"\"\"\n",
    "        # 1. Standard MSE loss\n",
    "        loss_mse = self.mse(pred, target)\n",
    "        \n",
    "        # 2. Monotonicity constraint (SOC should increase/decrease monotonically)\n",
    "        # Extract charge direction (feature index 9)\n",
    "        charge_direction = features[:, :, 9:10]  # [batch, seq_len, 1]\n",
    "        \n",
    "        # Compute SOC changes\n",
    "        soc_diff = pred[:, 1:, :] - pred[:, :-1, :]  # [batch, seq_len-1, 1]\n",
    "        expected_sign = charge_direction[:, 1:, :]  # [batch, seq_len-1, 1]\n",
    "        \n",
    "        # Penalize when SOC changes in wrong direction\n",
    "        # For charging (sign=+1), soc_diff should be positive\n",
    "        # For discharging (sign=-1), soc_diff should be negative\n",
    "        monotonic_violation = torch.relu(-soc_diff * expected_sign)\n",
    "        loss_monotonic = torch.mean(monotonic_violation)\n",
    "        \n",
    "        # 3. Coulomb counting consistency\n",
    "        # Compare predicted SOC with integrated current (feature index 10: q_norm)\n",
    "        q_norm = features[:, :, 10:11]  # [batch, seq_len, 1]\n",
    "        # q_norm is already normalized to [0, 1], so compare directly\n",
    "        loss_coulomb = torch.mean((pred - q_norm) ** 2)\n",
    "        \n",
    "        # Total loss\n",
    "        total_loss = (self.lambda_mse * loss_mse + \n",
    "                     self.lambda_monotonic * loss_monotonic +\n",
    "                     self.lambda_coulomb * loss_coulomb)\n",
    "        \n",
    "        return total_loss, loss_mse, loss_monotonic, loss_coulomb\n",
    "\n",
    "model = PhysicsInformedGRU(input_dim=13, hidden=128, layers=2, dropout=0.2).to(device)\n",
    "print(f\"Physics-Informed GRU with {sum(p.numel() for p in model.parameters()):,} parameters\\n\")\n",
    "\n",
    "print(\"Physics-based features included:\")\n",
    "print(\"  1. Voltage (V)\")\n",
    "print(\"  2. Temperature (T)\")\n",
    "print(\"  3. Current (I)\")\n",
    "print(\"  4. Voltage derivative (dV/dt)\")\n",
    "print(\"  5. Cumulative charge (I dt)\")\n",
    "print(\"  6. Temperature derivative (dT/dt)\")\n",
    "print(\"  7. Approximate resistance (V/I)\")\n",
    "print(\"  8. Power (V*I)\")\n",
    "print(\"  9. Cumulative energy (P dt)\")\n",
    "print(\" 10. Charge direction indicator\")\n",
    "print(\" 11. Normalized capacity (Coulomb counting)\")\n",
    "print(\" 12. OCV deviation\")\n",
    "print(\" 13. Temperature-compensated voltage\\n\")\n",
    "\n",
    "# -------------------- Training --------------------\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', \n",
    "                                                        factor=0.5, patience=10)\n",
    "physics_loss_fn = PhysicsInformedLoss(lambda_mse=1.0, lambda_monotonic=0.1, lambda_coulomb=0.05)\n",
    "\n",
    "epochs = 100\n",
    "best_loss = float('inf')\n",
    "\n",
    "print(\"Training Physics-Informed GRU...\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_mse = 0.0\n",
    "    train_mono = 0.0\n",
    "    train_coulomb = 0.0\n",
    "    \n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(xb)\n",
    "        \n",
    "        # Physics-informed loss\n",
    "        loss, mse, mono, coulomb = physics_loss_fn(pred, yb, xb)\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item() * xb.size(0)\n",
    "        train_mse += mse.item() * xb.size(0)\n",
    "        train_mono += mono.item() * xb.size(0)\n",
    "        train_coulomb += coulomb.item() * xb.size(0)\n",
    "    \n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_mse /= len(train_loader.dataset)\n",
    "    train_mono /= len(train_loader.dataset)\n",
    "    train_coulomb /= len(train_loader.dataset)\n",
    "    \n",
    "    # Validate\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_mse = 0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            pred = model(xb)\n",
    "            loss, mse, _, _ = physics_loss_fn(pred, yb, xb)\n",
    "            test_loss += loss.item() * xb.size(0)\n",
    "            test_mse += mse.item() * xb.size(0)\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_mse /= len(test_loader.dataset)\n",
    "    \n",
    "    # Learning rate scheduling\n",
    "    scheduler.step(test_loss)\n",
    "    \n",
    "    # Save best model\n",
    "    if test_loss < best_loss:\n",
    "        best_loss = test_loss\n",
    "        torch.save(model.state_dict(), 'best_pigru.pt')\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1:03d} | \"\n",
    "              f\"Train: {train_loss:.6f} (MSE: {train_mse:.6f}, Mono: {train_mono:.6f}, Coulomb: {train_coulomb:.6f}) | \"\n",
    "              f\"Test: {test_loss:.6f}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Best Test Loss: {best_loss:.6f}\\n\")\n",
    "\n",
    "# -------------------- Validation --------------------\n",
    "model.load_state_dict(torch.load('best_pigru.pt'))\n",
    "model.eval()\n",
    "\n",
    "# Get predictions\n",
    "predictions, actuals = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        pred = model(xb).cpu().numpy()\n",
    "        predictions.append(pred)\n",
    "        actuals.append(yb.numpy())\n",
    "\n",
    "predictions = np.concatenate(predictions) * 100  # Convert back to %\n",
    "actuals = np.concatenate(actuals) * 100\n",
    "\n",
    "# Calculate overall metrics\n",
    "mae = np.mean(np.abs(predictions - actuals))\n",
    "rmse = np.sqrt(np.mean((predictions - actuals)**2))\n",
    "max_error = np.max(np.abs(predictions - actuals))\n",
    "\n",
    "print(f\"{'='*60}\")\n",
    "print(\"Overall Validation Metrics (Physics-Informed GRU):\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"MAE:        {mae:.4f}%\")\n",
    "print(f\"RMSE:       {rmse:.4f}%\")\n",
    "print(f\"Max Error:  {max_error:.4f}%\")\n",
    "\n",
    "# -------------------- SOC Range Analysis --------------------\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SOC Range Analysis\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Define SOC ranges to test\n",
    "soc_ranges = [\n",
    "    (0, 30, \"Low SOC (0-30%)\"),\n",
    "    (30, 60, \"Mid SOC (30-60%)\"),\n",
    "    (60, 90, \"High SOC (60-90%)\"),\n",
    "    (0, 100, \"Full Range (0-100%)\")\n",
    "]\n",
    "\n",
    "range_metrics = []\n",
    "\n",
    "for soc_min, soc_max, range_name in soc_ranges:\n",
    "    # Filter predictions and actuals for this SOC range\n",
    "    mask = (actuals >= soc_min) & (actuals <= soc_max)\n",
    "    \n",
    "    if np.sum(mask) == 0:\n",
    "        print(f\"\\n{range_name}: No data points in this range\")\n",
    "        continue\n",
    "    \n",
    "    range_preds = predictions[mask]\n",
    "    range_actuals = actuals[mask]\n",
    "    \n",
    "    # Calculate metrics for this range\n",
    "    range_mae = np.mean(np.abs(range_preds - range_actuals))\n",
    "    range_rmse = np.sqrt(np.mean((range_preds - range_actuals)**2))\n",
    "    range_max_error = np.max(np.abs(range_preds - range_actuals))\n",
    "    n_points = np.sum(mask)\n",
    "    \n",
    "    range_metrics.append({\n",
    "        'Range': range_name,\n",
    "        'MAE': range_mae,\n",
    "        'RMSE': range_rmse,\n",
    "        'Max Error': range_max_error,\n",
    "        'N Points': n_points\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{range_name}:\")\n",
    "    print(f\"  Points:     {n_points:,}\")\n",
    "    print(f\"  MAE:        {range_mae:.4f}%\")\n",
    "    print(f\"  RMSE:       {range_rmse:.4f}%\")\n",
    "    print(f\"  Max Error:  {range_max_error:.4f}%\")\n",
    "\n",
    "# Create DataFrame for easier visualization\n",
    "metrics_df = pd.DataFrame(range_metrics)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Summary Table:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(metrics_df.to_string(index=False))\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# -------------------- Phase-specific Analysis --------------------\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Charging vs Discharging Analysis\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "phase_metrics = []\n",
    "\n",
    "for phase_type in ['C1ch', 'C1dc']:\n",
    "    phase_name = \"Charging\" if phase_type == 'C1ch' else \"Discharging\"\n",
    "    \n",
    "    # Get indices for this phase\n",
    "    phase_mask = phases_test == phase_type\n",
    "    \n",
    "    if np.sum(phase_mask) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Get predictions for this phase\n",
    "    phase_preds = predictions[phase_mask]\n",
    "    phase_actuals = actuals[phase_mask]\n",
    "    \n",
    "    # Overall phase metrics\n",
    "    phase_mae = np.mean(np.abs(phase_preds - phase_actuals))\n",
    "    phase_rmse = np.sqrt(np.mean((phase_preds - phase_actuals)**2))\n",
    "    \n",
    "    print(f\"\\n{phase_name}:\")\n",
    "    print(f\"  Sequences:  {np.sum(phase_mask)}\")\n",
    "    print(f\"  MAE:        {phase_mae:.4f}%\")\n",
    "    print(f\"  RMSE:       {phase_rmse:.4f}%\")\n",
    "    \n",
    "    # Break down by SOC ranges\n",
    "    for soc_min, soc_max, range_name in soc_ranges[:3]:  # Only low, mid, high\n",
    "        range_mask = (phase_actuals >= soc_min) & (phase_actuals <= soc_max)\n",
    "        \n",
    "        if np.sum(range_mask) > 0:\n",
    "            sub_preds = phase_preds[range_mask]\n",
    "            sub_actuals = phase_actuals[range_mask]\n",
    "            sub_mae = np.mean(np.abs(sub_preds - sub_actuals))\n",
    "            sub_rmse = np.sqrt(np.mean((sub_preds - sub_actuals)**2))\n",
    "            \n",
    "            print(f\"    {range_name}:\")\n",
    "            print(f\"      Points: {np.sum(range_mask):,} | MAE: {sub_mae:.4f}% | RMSE: {sub_rmse:.4f}%\")\n",
    "            \n",
    "            phase_metrics.append({\n",
    "                'Phase': phase_name,\n",
    "                'Range': range_name,\n",
    "                'MAE': sub_mae,\n",
    "                'RMSE': sub_rmse,\n",
    "                'N Points': np.sum(range_mask)\n",
    "            })\n",
    "\n",
    "# -------------------- Partial Curve Testing --------------------\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Testing on Partial Charge/Discharge Curves\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "def create_partial_curve(X_seq, y_seq, soc_start, soc_end):\n",
    "    \"\"\"Extract a partial curve from a full charge/discharge sequence.\"\"\"\n",
    "    soc_values = y_seq[:, 0]\n",
    "    \n",
    "    # Find indices where SOC is within the range\n",
    "    if soc_start < soc_end:  # Charging direction\n",
    "        mask = (soc_values >= soc_start) & (soc_values <= soc_end)\n",
    "    else:  # Discharging direction\n",
    "        mask = (soc_values <= soc_start) & (soc_values >= soc_end)\n",
    "    \n",
    "    if np.sum(mask) < 10:  # Need at least 10 points\n",
    "        return None, None\n",
    "    \n",
    "    indices = np.where(mask)[0]\n",
    "    start_idx, end_idx = indices[0], indices[-1] + 1\n",
    "    \n",
    "    return X_seq[start_idx:end_idx], y_seq[start_idx:end_idx]\n",
    "\n",
    "# Define partial curve test cases\n",
    "partial_curve_tests = [\n",
    "    # Charging scenarios\n",
    "    (0, 30, 'C1ch', 'Charge 0-30%'),\n",
    "    (30, 60, 'C1ch', 'Charge 30-60%'),\n",
    "    (60, 90, 'C1ch', 'Charge 60-90%'),\n",
    "    (20, 80, 'C1ch', 'Charge 20-80%'),\n",
    "    \n",
    "    # Discharging scenarios\n",
    "    (100, 70, 'C1dc', 'Discharge 100-70%'),\n",
    "    (70, 40, 'C1dc', 'Discharge 70-40%'),\n",
    "    (40, 10, 'C1dc', 'Discharge 40-10%'),\n",
    "    (80, 20, 'C1dc', 'Discharge 80-20%'),\n",
    "]\n",
    "\n",
    "partial_results = []\n",
    "\n",
    "for soc_start, soc_end, phase_type, test_name in partial_curve_tests:\n",
    "    # Find test sequences of the right phase\n",
    "    phase_mask = phases_test == phase_type\n",
    "    phase_indices = np.where(phase_mask)[0]\n",
    "    \n",
    "    if len(phase_indices) == 0:\n",
    "        print(f\"\\n{test_name}: No {phase_type} sequences available\")\n",
    "        continue\n",
    "    \n",
    "    # Process multiple sequences for this test case\n",
    "    test_preds, test_actuals = [], []\n",
    "    valid_sequences = 0\n",
    "    \n",
    "    for idx in phase_indices[:50]:  # Test on up to 50 sequences\n",
    "        X_seq = X_test[idx]\n",
    "        y_seq = y_test[idx]\n",
    "        \n",
    "        # Create partial curve\n",
    "        X_partial, y_partial = create_partial_curve(X_seq, y_seq, soc_start, soc_end)\n",
    "        \n",
    "        if X_partial is None:\n",
    "            continue\n",
    "        \n",
    "        valid_sequences += 1\n",
    "        \n",
    "        # Get prediction for partial curve\n",
    "        with torch.no_grad():\n",
    "            x_input = torch.tensor(X_partial[np.newaxis, :, :], dtype=torch.float32, device=device)\n",
    "            pred = model(x_input).cpu().numpy()[0, :, 0] * 100\n",
    "        \n",
    "        true = y_partial[:, 0]\n",
    "        \n",
    "        test_preds.append(pred)\n",
    "        test_actuals.append(true)\n",
    "    \n",
    "    if valid_sequences == 0:\n",
    "        print(f\"\\n{test_name}: No valid partial curves found in range\")\n",
    "        continue\n",
    "    \n",
    "    # Concatenate all predictions\n",
    "    all_preds = np.concatenate(test_preds)\n",
    "    all_actuals = np.concatenate(test_actuals)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae_partial = np.mean(np.abs(all_preds - all_actuals))\n",
    "    rmse_partial = np.sqrt(np.mean((all_preds - all_actuals)**2))\n",
    "    max_error_partial = np.max(np.abs(all_preds - all_actuals))\n",
    "    \n",
    "    partial_results.append({\n",
    "        'Test': test_name,\n",
    "        'Phase': phase_type,\n",
    "        'SOC Range': f\"{soc_start}-{soc_end}%\",\n",
    "        'Sequences': valid_sequences,\n",
    "        'Points': len(all_preds),\n",
    "        'MAE': mae_partial,\n",
    "        'RMSE': rmse_partial,\n",
    "        'Max Error': max_error_partial\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{test_name}:\")\n",
    "    print(f\"  Valid Sequences: {valid_sequences}\")\n",
    "    print(f\"  Total Points:    {len(all_preds):,}\")\n",
    "    print(f\"  MAE:             {mae_partial:.4f}%\")\n",
    "    print(f\"  RMSE:            {rmse_partial:.4f}%\")\n",
    "    print(f\"  Max Error:       {max_error_partial:.4f}%\")\n",
    "\n",
    "# Create summary table\n",
    "if len(partial_results) > 0:\n",
    "    partial_df = pd.DataFrame(partial_results)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Partial Curve Testing Summary:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(partial_df.to_string(index=False))\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "# -------------------- Visualizations --------------------\n",
    "print(\"Generating visualizations...\\n\")\n",
    "\n",
    "# 1. Partial Curve Visualization\n",
    "fig, axes = plt.subplots(4, 2, figsize=(14, 16))\n",
    "\n",
    "visualization_tests = [\n",
    "    (0, 30, 'C1ch', 'Charge 0-30%', 0, 0),\n",
    "    (30, 60, 'C1ch', 'Charge 30-60%', 0, 1),\n",
    "    (60, 90, 'C1ch', 'Charge 60-90%', 1, 0),\n",
    "    (20, 80, 'C1ch', 'Charge 20-80%', 1, 1),\n",
    "    (100, 70, 'C1dc', 'Discharge 100-70%', 2, 0),\n",
    "    (70, 40, 'C1dc', 'Discharge 70-40%', 2, 1),\n",
    "    (40, 10, 'C1dc', 'Discharge 40-10%', 3, 0),\n",
    "    (80, 20, 'C1dc', 'Discharge 80-20%', 3, 1),\n",
    "]\n",
    "\n",
    "for soc_start, soc_end, phase_type, test_name, row, col in visualization_tests:\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    # Find a suitable test sequence\n",
    "    phase_mask = phases_test == phase_type\n",
    "    phase_indices = np.where(phase_mask)[0]\n",
    "    \n",
    "    found = False\n",
    "    for idx in phase_indices[:100]:\n",
    "        X_seq = X_test[idx]\n",
    "        y_seq = y_test[idx]\n",
    "        \n",
    "        # Create partial curve\n",
    "        X_partial, y_partial = create_partial_curve(X_seq, y_seq, soc_start, soc_end)\n",
    "        \n",
    "        if X_partial is None or len(X_partial) < 10:\n",
    "            continue\n",
    "        \n",
    "        # Get prediction\n",
    "        with torch.no_grad():\n",
    "            x_input = torch.tensor(X_partial[np.newaxis, :, :], dtype=torch.float32, device=device)\n",
    "            pred = model(x_input).cpu().numpy()[0, :, 0] * 100\n",
    "        \n",
    "        true = y_partial[:, 0]\n",
    "        error = np.abs(true - pred)\n",
    "        mae_sample = np.mean(error)\n",
    "        max_error_sample = np.max(error)\n",
    "        \n",
    "        # Plot\n",
    "        time_steps = np.arange(len(true))\n",
    "        ax.plot(time_steps, true, 'b-', linewidth=2.5, label='True SOC', alpha=0.8)\n",
    "        ax.plot(time_steps, pred, 'r--', linewidth=2, label='PI-GRU Prediction', alpha=0.8)\n",
    "        ax.fill_between(time_steps, true, pred, alpha=0.2, color='orange')\n",
    "        \n",
    "        # Add horizontal lines for SOC range\n",
    "        ax.axhline(soc_start, color='green', linestyle=':', linewidth=1.5, alpha=0.7, label=f'Start: {soc_start}%')\n",
    "        ax.axhline(soc_end, color='red', linestyle=':', linewidth=1.5, alpha=0.7, label=f'End: {soc_end}%')\n",
    "        \n",
    "        ax.set_title(f'{test_name}\\nMAE: {mae_sample:.2f}% | Max Error: {max_error_sample:.2f}%', \n",
    "                     fontsize=10, fontweight='bold')\n",
    "        ax.set_xlabel('Time Step', fontsize=9)\n",
    "        ax.set_ylabel('SOC (%)', fontsize=9)\n",
    "        ax.legend(fontsize=7, loc='best')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_ylim(max(0, min(soc_start, soc_end) - 10), \n",
    "                    min(100, max(soc_start, soc_end) + 10))\n",
    "        \n",
    "        found = True\n",
    "        break\n",
    "    \n",
    "    if not found:\n",
    "        ax.text(0.5, 0.5, f'No valid\\n{test_name}\\ndata found',\n",
    "               ha='center', va='center', fontsize=10, transform=ax.transAxes)\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "plt.suptitle('Physics-Informed GRU Performance on Partial Curves', \n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Comparison: Partial Curves MAE/RMSE\n",
    "if len(partial_results) > 0:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    charging_partial = partial_df[partial_df['Phase'] == 'C1ch']\n",
    "    discharging_partial = partial_df[partial_df['Phase'] == 'C1dc']\n",
    "    \n",
    "    # Plot MAE comparison\n",
    "    ax = axes[0]\n",
    "    if len(charging_partial) > 0:\n",
    "        x_charge = np.arange(len(charging_partial))\n",
    "        ax.bar(x_charge - 0.2, charging_partial['MAE'], 0.4, \n",
    "               label='Charging', alpha=0.8, color='green')\n",
    "    if len(discharging_partial) > 0:\n",
    "        x_discharge = np.arange(len(discharging_partial))\n",
    "        ax.bar(x_discharge + 0.2, discharging_partial['MAE'], 0.4, \n",
    "               label='Discharging', alpha=0.8, color='orange')\n",
    "    \n",
    "    all_tests = pd.concat([charging_partial, discharging_partial]) if len(discharging_partial) > 0 else charging_partial\n",
    "    ax.set_xticks(np.arange(len(all_tests)))\n",
    "    ax.set_xticklabels([t.replace('Charge ', 'C ').replace('Discharge ', 'D ') \n",
    "                        for t in all_tests['Test']], rotation=45, ha='right')\n",
    "    ax.set_ylabel('MAE (%)')\n",
    "    ax.set_title('MAE for Partial Curves (PI-GRU)', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot RMSE comparison\n",
    "    ax = axes[1]\n",
    "    if len(charging_partial) > 0:\n",
    "        ax.bar(x_charge - 0.2, charging_partial['RMSE'], 0.4, \n",
    "               label='Charging', alpha=0.8, color='green')\n",
    "    if len(discharging_partial) > 0:\n",
    "        ax.bar(x_discharge + 0.2, discharging_partial['RMSE'], 0.4, \n",
    "               label='Discharging', alpha=0.8, color='orange')\n",
    "    \n",
    "    ax.set_xticks(np.arange(len(all_tests)))\n",
    "    ax.set_xticklabels([t.replace('Charge ', 'C ').replace('Discharge ', 'D ') \n",
    "                        for t in all_tests['Test']], rotation=45, ha='right')\n",
    "    ax.set_ylabel('RMSE (%)')\n",
    "    ax.set_title('RMSE for Partial Curves (PI-GRU)', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 3. Range-specific Visualization\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "ax = axes[0, 0]\n",
    "x_pos = np.arange(len(range_metrics))\n",
    "ax.bar(x_pos, [m['MAE'] for m in range_metrics], alpha=0.7, color='steelblue')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([m['Range'].split('(')[0].strip() for m in range_metrics], rotation=45, ha='right')\n",
    "ax.set_ylabel('MAE (%)')\n",
    "ax.set_title('MAE by SOC Range (PI-GRU)', fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "ax = axes[0, 1]\n",
    "ax.bar(x_pos, [m['RMSE'] for m in range_metrics], alpha=0.7, color='coral')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([m['Range'].split('(')[0].strip() for m in range_metrics], rotation=45, ha='right')\n",
    "ax.set_ylabel('RMSE (%)')\n",
    "ax.set_title('RMSE by SOC Range (PI-GRU)', fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "ax = axes[0, 2]\n",
    "ax.bar(x_pos, [m['Max Error'] for m in range_metrics], alpha=0.7, color='lightcoral')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([m['Range'].split('(')[0].strip() for m in range_metrics], rotation=45, ha='right')\n",
    "ax.set_ylabel('Max Error (%)')\n",
    "ax.set_title('Max Error by SOC Range (PI-GRU)', fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Error distribution by range\n",
    "for idx, (soc_min, soc_max, range_name) in enumerate(soc_ranges[:3]):\n",
    "    ax = axes[1, idx]\n",
    "    mask = (actuals >= soc_min) & (actuals <= soc_max)\n",
    "    \n",
    "    if np.sum(mask) > 0:\n",
    "        range_errors = (predictions[mask] - actuals[mask]).flatten()\n",
    "        ax.hist(range_errors, bins=30, edgecolor='black', alpha=0.7, color='teal')\n",
    "        ax.axvline(0, color='red', linestyle='--', linewidth=2, label='Zero Error')\n",
    "        ax.set_xlabel('Error (%)')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        ax.set_title(f'{range_name}\\nMean Error: {np.mean(range_errors):.3f}%', fontweight='bold')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Physics-Informed GRU SOC Range Analysis', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 4. Phase-specific Visualization\n",
    "if len(phase_metrics) > 0:\n",
    "    phase_df = pd.DataFrame(phase_metrics)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    ax = axes[0]\n",
    "    ranges_unique = phase_df['Range'].unique()\n",
    "    x = np.arange(len(ranges_unique))\n",
    "    width = 0.35\n",
    "    \n",
    "    charging_data = phase_df[phase_df['Phase'] == 'Charging']\n",
    "    discharging_data = phase_df[phase_df['Phase'] == 'Discharging']\n",
    "    \n",
    "    charge_mae = [charging_data[charging_data['Range'] == r]['MAE'].values[0] \n",
    "                  if len(charging_data[charging_data['Range'] == r]) > 0 else 0 \n",
    "                  for r in ranges_unique]\n",
    "    discharge_mae = [discharging_data[discharging_data['Range'] == r]['MAE'].values[0] \n",
    "                     if len(discharging_data[discharging_data['Range'] == r]) > 0 else 0 \n",
    "                     for r in ranges_unique]\n",
    "    \n",
    "    ax.bar(x - width/2, charge_mae, width, label='Charging', alpha=0.8, color='green')\n",
    "    ax.bar(x + width/2, discharge_mae, width, label='Discharging', alpha=0.8, color='orange')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([r.split('(')[0].strip() for r in ranges_unique], rotation=45, ha='right')\n",
    "    ax.set_ylabel('MAE (%)')\n",
    "    ax.set_title('MAE: Charging vs Discharging (PI-GRU)', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    ax = axes[1]\n",
    "    charge_rmse = [charging_data[charging_data['Range'] == r]['RMSE'].values[0] \n",
    "                   if len(charging_data[charging_data['Range'] == r]) > 0 else 0 \n",
    "                   for r in ranges_unique]\n",
    "    discharge_rmse = [discharging_data[discharging_data['Range'] == r]['RMSE'].values[0] \n",
    "                      if len(discharging_data[discharging_data['Range'] == r]) > 0 else 0 \n",
    "                      for r in ranges_unique]\n",
    "    \n",
    "    ax.bar(x - width/2, charge_rmse, width, label='Charging', alpha=0.8, color='green')\n",
    "    ax.bar(x + width/2, discharge_rmse, width, label='Discharging', alpha=0.8, color='orange')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([r.split('(')[0].strip() for r in ranges_unique], rotation=45, ha='right')\n",
    "    ax.set_ylabel('RMSE (%)')\n",
    "    ax.set_title('RMSE: Charging vs Discharging (PI-GRU)', fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 5. Sample Predictions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "for i in range(4):\n",
    "    idx = np.random.randint(0, len(X_test))\n",
    "    with torch.no_grad():\n",
    "        x_sample = torch.tensor(X_test[idx:idx+1], dtype=torch.float32, device=device)\n",
    "        pred = model(x_sample).cpu().numpy()[0, :, 0] * 100\n",
    "    \n",
    "    true = y_test[idx, :, 0]\n",
    "    error = np.mean(np.abs(true - pred))\n",
    "    phase_label = \"Charging\" if phases_test[idx] == 'C1ch' else \"Discharging\"\n",
    "    \n",
    "    ax = axes[i//2, i%2]\n",
    "    ax.plot(true, 'k-', linewidth=2, label='True SOC')\n",
    "    ax.plot(pred, 'r--', linewidth=2, label='PI-GRU Prediction')\n",
    "    ax.set_title(f'{phase_label} - Sample {i+1} | MAE: {error:.2f}%', \n",
    "                 fontsize=11, fontweight='bold')\n",
    "    ax.set_xlabel('Time Step')\n",
    "    ax.set_ylabel('SOC (%)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Physics-Informed GRU SOC Estimation (Random Samples)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Overall Error Distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "errors = (predictions - actuals).flatten()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(errors, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Prediction Error (%)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Error Distribution (PI-GRU)')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(actuals.flatten(), predictions.flatten(), alpha=0.5, s=1)\n",
    "plt.plot([0, 100], [0, 100], 'r--', linewidth=2, label='Perfect Prediction')\n",
    "plt.xlabel('True SOC (%)')\n",
    "plt.ylabel('Predicted SOC (%)')\n",
    "plt.title('Prediction vs Actual (PI-GRU)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDone! Physics-Informed GRU training and evaluation complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be67854-6326-4d09-8b5b-28b1ba077eff",
   "metadata": {},
   "source": [
    "GRU-PINN-AUGUMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca29b53-0dac-4b87-a155-3357c6f59daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# ============================================================\n",
    "# -------------------- Data Loading --------------------------\n",
    "# ============================================================\n",
    "data = scipy.io.loadmat('Oxford_Battery_Degradation_Dataset_1.mat')\n",
    "\n",
    "def soc_from_q(q, phase):\n",
    "    \"\"\"Compute SOC% from charge trace.\"\"\"\n",
    "    q0, q1 = float(q[0]), float(q[-1])\n",
    "    if np.isclose(q1, q0):\n",
    "        return None\n",
    "    qn = (q - q0) / (q1 - q0)\n",
    "    if phase == 'C1ch':\n",
    "        return 100.0 * np.clip(qn, 0, 1)\n",
    "    elif phase == 'C1dc':\n",
    "        return 100.0 * (1.0 - np.clip(qn, 0, 1))\n",
    "    return None\n",
    "\n",
    "def extract_sequences(data, L=128):\n",
    "    \"\"\"Extract V, T, I features and SOC labels.\"\"\"\n",
    "    X_list, y_list, phase_list = [], [], []\n",
    "    \n",
    "    for ci in range(1, 9):\n",
    "        cell = data[f'Cell{ci}']\n",
    "        for cyc_name in sorted(cell.dtype.names, key=lambda s: int(s[3:])):\n",
    "            cyc = cell[cyc_name][0, 0]\n",
    "            for phase in ['C1ch', 'C1dc']:\n",
    "                if phase not in cyc.dtype.names:\n",
    "                    continue\n",
    "                blk = cyc[phase][0, 0]\n",
    "                if not all(k in blk.dtype.names for k in ['t','v','q']):\n",
    "                    continue\n",
    "                \n",
    "                t = blk['t'][0,0].ravel().astype(float)\n",
    "                v = blk['v'][0,0].ravel().astype(float)\n",
    "                q = blk['q'][0,0].ravel().astype(float)\n",
    "                \n",
    "                if t.size < 5:\n",
    "                    continue\n",
    "                \n",
    "                # Temperature (fill missing with forward/backward fill)\n",
    "                if 'T' in blk.dtype.names:\n",
    "                    T = blk['T'][0,0].ravel().astype(float)\n",
    "                else:\n",
    "                    T = np.full_like(t, 25.0)\n",
    "                T = pd.Series(T).ffill().bfill().values\n",
    "                \n",
    "                # Current (use defaults if missing)\n",
    "                if 'i' in blk.dtype.names:\n",
    "                    I = blk['i'][0,0].ravel().astype(float)\n",
    "                else:\n",
    "                    I = np.full_like(t, 0.74 if phase == 'C1ch' else -0.74)\n",
    "                \n",
    "                soc = soc_from_q(q, phase)\n",
    "                if soc is None:\n",
    "                    continue\n",
    "                \n",
    "                # Resample to fixed length L\n",
    "                t_new = np.linspace(t[0], t[-1], L)\n",
    "                v_new = np.interp(t_new, t, v)\n",
    "                T_new = np.interp(t_new, t, T)\n",
    "                I_new = np.interp(t_new, t, I)\n",
    "                y_new = np.interp(t_new, t, soc)\n",
    "                \n",
    "                X = np.stack([v_new, T_new, I_new], axis=-1)  # [L, 3]\n",
    "                y = y_new[:, None]  # [L, 1]\n",
    "                \n",
    "                X_list.append(X)\n",
    "                y_list.append(y)\n",
    "                phase_list.append(phase)\n",
    "    \n",
    "    return np.array(X_list), np.array(y_list), np.array(phase_list)\n",
    "\n",
    "# ============================================================\n",
    "# ------------- Data Augmentation for Mid-SOC ----------------\n",
    "# ============================================================\n",
    "def augment_with_partial_curves(X, y, phases, augmentation_factor=3):\n",
    "    \"\"\"\n",
    "    Augment dataset by extracting partial curves from different SOC ranges.\n",
    "    This creates more training examples, especially for mid-SOC regions.\n",
    "    \n",
    "    Args:\n",
    "        X: [N, L, 3] - features\n",
    "        y: [N, L, 1] - SOC labels (in %)\n",
    "        phases: [N] - phase labels\n",
    "        augmentation_factor: how many partial curves to extract per sequence\n",
    "    \n",
    "    Returns:\n",
    "        Augmented X, y, phases\n",
    "    \"\"\"\n",
    "    X_aug, y_aug, phase_aug = [], [], []\n",
    "    \n",
    "    # Keep all original sequences\n",
    "    for i in range(len(X)):\n",
    "        X_aug.append(X[i])\n",
    "        y_aug.append(y[i])\n",
    "        phase_aug.append(phases[i])\n",
    "    \n",
    "    # Define partial curve ranges with emphasis on mid-SOC\n",
    "    # Format: (start_soc, end_soc, weight) - weight determines sampling probability\n",
    "    if phases[0] == 'C1ch':  # Charging ranges\n",
    "        partial_ranges = [\n",
    "            (0, 40, 1.0),    # Early charging\n",
    "            (10, 50, 2.0),   # Early-mid charging (overlap with mid)\n",
    "            (20, 60, 3.0),   # Mid charging (HIGH WEIGHT)\n",
    "            (30, 70, 3.0),   # Mid charging (HIGH WEIGHT)\n",
    "            (40, 80, 2.0),   # Mid-late charging\n",
    "            (50, 90, 1.0),   # Late charging\n",
    "            (60, 100, 1.0),  # Very late charging\n",
    "        ]\n",
    "    else:  # Discharging ranges\n",
    "        partial_ranges = [\n",
    "            (100, 60, 1.0),  # Early discharging\n",
    "            (90, 50, 2.0),   # Early-mid discharging\n",
    "            (80, 40, 3.0),   # Mid discharging (HIGH WEIGHT)\n",
    "            (70, 30, 3.0),   # Mid discharging (HIGH WEIGHT)\n",
    "            (60, 20, 2.0),   # Mid-late discharging\n",
    "            (50, 10, 1.0),   # Late discharging\n",
    "            (40, 0, 1.0),    # Very late discharging\n",
    "        ]\n",
    "    \n",
    "    print(f\"\\nAugmenting data with partial curves...\")\n",
    "    print(f\"Original sequences: {len(X)}\")\n",
    "    \n",
    "    augmented_count = 0\n",
    "    \n",
    "    for i in range(len(X)):\n",
    "        soc_values = y[i, :, 0]\n",
    "        phase = phases[i]\n",
    "        \n",
    "        # Sample partial ranges based on weights\n",
    "        for _ in range(augmentation_factor):\n",
    "            # Choose range based on weights\n",
    "            ranges = [r for r in partial_ranges]\n",
    "            weights = [r[2] for r in ranges]\n",
    "            weights = np.array(weights) / np.sum(weights)\n",
    "            \n",
    "            chosen_idx = np.random.choice(len(ranges), p=weights)\n",
    "            soc_start, soc_end, _ = ranges[chosen_idx]\n",
    "            \n",
    "            # Extract partial curve\n",
    "            if phase == 'C1ch':  # Charging\n",
    "                mask = (soc_values >= soc_start) & (soc_values <= soc_end)\n",
    "            else:  # Discharging\n",
    "                mask = (soc_values <= soc_start) & (soc_values >= soc_end)\n",
    "            \n",
    "            if np.sum(mask) < 20:  # Need reasonable number of points\n",
    "                continue\n",
    "            \n",
    "            indices = np.where(mask)[0]\n",
    "            start_idx, end_idx = indices[0], indices[-1] + 1\n",
    "            \n",
    "            # Extract and pad/truncate to fixed length\n",
    "            X_partial = X[i, start_idx:end_idx, :]\n",
    "            y_partial = y[i, start_idx:end_idx, :]\n",
    "            \n",
    "            # Pad or sample to target length (64 for partial curves)\n",
    "            target_len = 64\n",
    "            if len(X_partial) < target_len:\n",
    "                # Pad with last values\n",
    "                pad_len = target_len - len(X_partial)\n",
    "                X_partial = np.vstack([X_partial, np.tile(X_partial[-1:], (pad_len, 1))])\n",
    "                y_partial = np.vstack([y_partial, np.tile(y_partial[-1:], (pad_len, 1))])\n",
    "            else:\n",
    "                # Resample to target length\n",
    "                indices_sample = np.linspace(0, len(X_partial)-1, target_len, dtype=int)\n",
    "                X_partial = X_partial[indices_sample]\n",
    "                y_partial = y_partial[indices_sample]\n",
    "            \n",
    "            X_aug.append(X_partial)\n",
    "            y_aug.append(y_partial)\n",
    "            phase_aug.append(phase)\n",
    "            augmented_count += 1\n",
    "    \n",
    "    print(f\"Added {augmented_count} augmented partial curves\")\n",
    "    print(f\"Total sequences after augmentation: {len(X_aug)}\")\n",
    "    \n",
    "    # Convert to arrays\n",
    "    # Need to handle different lengths - pad shorter sequences\n",
    "    max_len = max(x.shape[0] for x in X_aug)\n",
    "    \n",
    "    X_padded = []\n",
    "    y_padded = []\n",
    "    \n",
    "    for i in range(len(X_aug)):\n",
    "        x_seq = X_aug[i]\n",
    "        y_seq = y_aug[i]\n",
    "        \n",
    "        if x_seq.shape[0] < max_len:\n",
    "            pad_len = max_len - x_seq.shape[0]\n",
    "            x_seq = np.vstack([x_seq, np.tile(x_seq[-1:], (pad_len, 1))])\n",
    "            y_seq = np.vstack([y_seq, np.tile(y_seq[-1:], (pad_len, 1))])\n",
    "        \n",
    "        X_padded.append(x_seq)\n",
    "        y_padded.append(y_seq)\n",
    "    \n",
    "    return np.array(X_padded), np.array(y_padded), np.array(phase_aug)\n",
    "\n",
    "# ============================================================\n",
    "# -------------------- Prepare Data --------------------------\n",
    "# ============================================================\n",
    "print(\"Loading data...\")\n",
    "X_raw, y_raw, phases_raw = extract_sequences(data, L=128)\n",
    "print(f\"Raw sequences: {len(X_raw)}, Shape: {X_raw.shape}\")\n",
    "\n",
    "# Train/test split BEFORE augmentation (to avoid data leakage)\n",
    "n_train = int(0.8 * len(X_raw))\n",
    "X_train_raw, X_test = X_raw[:n_train], X_raw[n_train:]\n",
    "y_train_raw, y_test = y_raw[:n_train], y_raw[n_train:]\n",
    "phases_train_raw, phases_test = phases_raw[:n_train], phases_raw[n_train:]\n",
    "\n",
    "print(f\"\\nBefore augmentation:\")\n",
    "print(f\"  Train: {len(X_train_raw)} | Test: {len(X_test)}\")\n",
    "\n",
    "# Augment ONLY training data with partial curves\n",
    "X_train_aug, y_train_aug, phases_train_aug = augment_with_partial_curves(\n",
    "    X_train_raw, y_train_raw, phases_train_raw, augmentation_factor=3\n",
    ")\n",
    "\n",
    "print(f\"\\nAfter augmentation:\")\n",
    "print(f\"  Train: {len(X_train_aug)} | Test: {len(X_test)}\")\n",
    "\n",
    "# Normalize features using stats from ORIGINAL training data only\n",
    "mu = X_train_raw.reshape(-1, X_train_raw.shape[-1]).mean(axis=0)\n",
    "sd = X_train_raw.reshape(-1, X_train_raw.shape[-1]).std(axis=0) + 1e-8\n",
    "\n",
    "X_train = (X_train_aug - mu) / sd\n",
    "X_test = (X_test - mu) / sd\n",
    "\n",
    "# Normalize labels to [0, 1]\n",
    "y_train_norm = y_train_aug / 100.0\n",
    "y_test_norm = y_test / 100.0\n",
    "\n",
    "# ============================================================\n",
    "# -------------------- DataLoaders ---------------------------\n",
    "# ============================================================\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\nDevice: {device}\\n\")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                  torch.tensor(y_train_norm, dtype=torch.float32)),\n",
    "    batch_size=32, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    TensorDataset(torch.tensor(X_test, dtype=torch.float32),\n",
    "                  torch.tensor(y_test_norm, dtype=torch.float32)),\n",
    "    batch_size=32, shuffle=False)\n",
    "\n",
    "# ============================================================\n",
    "# -------------------- GRU-PINN Model ------------------------\n",
    "# ============================================================\n",
    "class GRU_PINN(nn.Module):\n",
    "    \"\"\"\n",
    "    Physics-informed GRU for SOC estimation.\n",
    "    - Base GRU learns mapping from (V, T, I) -> SOC\n",
    "    - Physics loss enforces discrete Coulomb counting:\n",
    "        SOC_{k+1} - SOC_k  alpha * I_k\n",
    "    - Bounds loss softly enforces SOC in [0, 1]\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=3, hidden=128, layers=2, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden, num_layers=layers,\n",
    "                          batch_first=True,\n",
    "                          dropout=dropout if layers > 1 else 0.0)\n",
    "        self.fc = nn.Linear(hidden, 1)\n",
    "\n",
    "        # Physics parameter: SOC increment per unit current per step (in normalized SOC units).\n",
    "        self.alpha = nn.Parameter(torch.tensor(1e-3, dtype=torch.float32))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch, seq_len, input_dim]\n",
    "        out, _ = self.gru(x)      # [batch, seq_len, hidden]\n",
    "        soc_hat = self.fc(out)    # [batch, seq_len, 1], normalized SOC\n",
    "        return soc_hat\n",
    "\n",
    "    def physics_loss(self, x, y_pred):\n",
    "        \"\"\"\n",
    "        Physics-informed loss based on discrete Coulomb counting:\n",
    "            SOC_{k+1} - SOC_k  alpha * I_k\n",
    "        \"\"\"\n",
    "        I = x[..., 2]          # [B, L] - Current\n",
    "        soc = y_pred[..., 0]   # [B, L]\n",
    "\n",
    "        dsoc = soc[:, 1:] - soc[:, :-1]  # [B, L-1]\n",
    "        I_mid = I[:, :-1]                # [B, L-1]\n",
    "\n",
    "        residual = dsoc - self.alpha * I_mid\n",
    "        phys_loss = (residual ** 2).mean()\n",
    "        return phys_loss\n",
    "\n",
    "    def bounds_loss(self, y_pred):\n",
    "        \"\"\"Softly enforce SOC in [0, 1].\"\"\"\n",
    "        below = torch.relu(-y_pred)\n",
    "        above = torch.relu(y_pred - 1.0)\n",
    "        return (below**2 + above**2).mean()\n",
    "\n",
    "model = GRU_PINN(input_dim=3, hidden=128, layers=2, dropout=0.2).to(device)\n",
    "print(f\"Model: GRU-PINN with {sum(p.numel() for p in model.parameters()):,} parameters\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# -------------------- Training (GRU-PINN) -------------------\n",
    "# ============================================================\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "epochs = 150\n",
    "best_loss = float('inf')\n",
    "\n",
    "# Physics / bounds weights\n",
    "lambda_phys = 0.1\n",
    "lambda_bounds = 0.01\n",
    "\n",
    "print(\"Training GRU-PINN model with augmented data...\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Train\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_mse = 0.0\n",
    "    train_phys = 0.0\n",
    "    train_bounds = 0.0\n",
    "    \n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(xb)\n",
    "\n",
    "        # Component losses\n",
    "        data_loss = loss_fn(y_pred, yb)\n",
    "        phys_loss = model.physics_loss(xb, y_pred)\n",
    "        bnd_loss = model.bounds_loss(y_pred)\n",
    "\n",
    "        # Total PINN loss\n",
    "        loss = data_loss + lambda_phys * phys_loss + lambda_bounds * bnd_loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * xb.size(0)\n",
    "        train_mse += data_loss.item() * xb.size(0)\n",
    "        train_phys += phys_loss.item() * xb.size(0)\n",
    "        train_bounds += bnd_loss.item() * xb.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "    train_mse /= len(train_loader.dataset)\n",
    "    train_phys /= len(train_loader.dataset)\n",
    "    train_bounds /= len(train_loader.dataset)\n",
    "\n",
    "    # Validate\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    test_mse = 0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            y_pred = model(xb)\n",
    "\n",
    "            data_loss = loss_fn(y_pred, yb)\n",
    "            phys_loss = model.physics_loss(xb, y_pred)\n",
    "            bnd_loss = model.bounds_loss(y_pred)\n",
    "\n",
    "            loss = data_loss + lambda_phys * phys_loss + lambda_bounds * bnd_loss\n",
    "            test_loss += loss.item() * xb.size(0)\n",
    "            test_mse += data_loss.item() * xb.size(0)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_mse /= len(test_loader.dataset)\n",
    "\n",
    "    # Save best model (based on test MSE for fair comparison)\n",
    "    if test_mse < best_loss:\n",
    "        best_loss = test_mse\n",
    "        torch.save(model.state_dict(), 'best_gru_pinn_augmented.pt')\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(\n",
    "            f\"Epoch {epoch+1:03d} | \"\n",
    "            f\"Train: {train_loss:.6f} (MSE: {train_mse:.6f}, Phys: {train_phys:.6f}, Bnd: {train_bounds:.6f}) | \"\n",
    "            f\"Test: {test_loss:.6f} (MSE: {test_mse:.6f}) | \"\n",
    "            f\"alpha: {model.alpha.item():.6e}\"\n",
    "        )\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Best Test MSE: {best_loss:.6f}\")\n",
    "print(f\"Learned alpha: {model.alpha.item():.6e}\")\n",
    "\n",
    "# ============================================================\n",
    "# -------------------- Validation ----------------------------\n",
    "# ============================================================\n",
    "model.load_state_dict(torch.load('best_gru_pinn_augmented.pt'))\n",
    "model.eval()\n",
    "\n",
    "# Get predictions on test set\n",
    "predictions, actuals = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        pred = model(xb).cpu().numpy()\n",
    "        predictions.append(pred)\n",
    "        actuals.append(yb.numpy())\n",
    "\n",
    "predictions = np.concatenate(predictions) * 100.0\n",
    "actuals = np.concatenate(actuals) * 100.0\n",
    "\n",
    "# Overall metrics\n",
    "mae = np.mean(np.abs(predictions - actuals))\n",
    "rmse = np.sqrt(np.mean((predictions - actuals)**2))\n",
    "max_error = np.max(np.abs(predictions - actuals))\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Overall Validation Metrics (GRU-PINN + Augmentation):\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"MAE:        {mae:.4f}%\")\n",
    "print(f\"RMSE:       {rmse:.4f}%\")\n",
    "print(f\"Max Error:  {max_error:.4f}%\")\n",
    "\n",
    "# ============================================================\n",
    "# -------------------- SOC Range Analysis --------------------\n",
    "# ============================================================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SOC Range Analysis (Emphasis on Mid-SOC)\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "soc_ranges = [\n",
    "    (0, 30, \"Low SOC (0-30%)\"),\n",
    "    (30, 60, \"Mid SOC (30-60%)\"),  # This should be much better now!\n",
    "    (60, 90, \"High SOC (60-90%)\"),\n",
    "    (0, 100, \"Full Range (0-100%)\")\n",
    "]\n",
    "\n",
    "range_metrics = []\n",
    "\n",
    "for soc_min, soc_max, range_name in soc_ranges:\n",
    "    mask = (actuals >= soc_min) & (actuals <= soc_max)\n",
    "    if np.sum(mask) == 0:\n",
    "        print(f\"\\n{range_name}: No data points in this range\")\n",
    "        continue\n",
    "    \n",
    "    range_preds = predictions[mask]\n",
    "    range_actuals = actuals[mask]\n",
    "    \n",
    "    range_mae = np.mean(np.abs(range_preds - range_actuals))\n",
    "    range_rmse = np.sqrt(np.mean((range_preds - range_actuals)**2))\n",
    "    range_max_error = np.max(np.abs(range_preds - range_actuals))\n",
    "    n_points = np.sum(mask)\n",
    "    \n",
    "    range_metrics.append({\n",
    "        'Range': range_name,\n",
    "        'MAE': range_mae,\n",
    "        'RMSE': range_rmse,\n",
    "        'Max Error': range_max_error,\n",
    "        'N Points': n_points\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{range_name}:\")\n",
    "    print(f\"  Points:     {n_points:,}\")\n",
    "    print(f\"  MAE:        {range_mae:.4f}%\")\n",
    "    print(f\"  RMSE:       {range_rmse:.4f}%\")\n",
    "    print(f\"  Max Error:  {range_max_error:.4f}%\")\n",
    "\n",
    "metrics_df = pd.DataFrame(range_metrics)\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Summary Table:\")\n",
    "print(f\"{'='*60}\")\n",
    "print(metrics_df.to_string(index=False))\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# ---------------- Charging vs Discharging -------------------\n",
    "# ============================================================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Charging vs Discharging Analysis\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "phase_metrics = []\n",
    "\n",
    "for phase_type in ['C1ch', 'C1dc']:\n",
    "    phase_name = \"Charging\" if phase_type == 'C1ch' else \"Discharging\"\n",
    "    \n",
    "    phase_mask = phases_test == phase_type\n",
    "    if np.sum(phase_mask) == 0:\n",
    "        continue\n",
    "    \n",
    "    phase_preds = predictions[phase_mask]\n",
    "    phase_actuals = actuals[phase_mask]\n",
    "    \n",
    "    phase_mae = np.mean(np.abs(phase_preds - phase_actuals))\n",
    "    phase_rmse = np.sqrt(np.mean((phase_preds - phase_actuals)**2))\n",
    "    \n",
    "    print(f\"\\n{phase_name}:\")\n",
    "    print(f\"  Sequences:  {np.sum(phase_mask)}\")\n",
    "    print(f\"  MAE:        {phase_mae:.4f}%\")\n",
    "    print(f\"  RMSE:       {phase_rmse:.4f}%\")\n",
    "    \n",
    "    for soc_min, soc_max, range_name in soc_ranges[:3]:\n",
    "        range_mask = (phase_actuals >= soc_min) & (phase_actuals <= soc_max)\n",
    "        \n",
    "        if np.sum(range_mask) > 0:\n",
    "            sub_preds = phase_preds[range_mask]\n",
    "            sub_actuals = phase_actuals[range_mask]\n",
    "            sub_mae = np.mean(np.abs(sub_preds - sub_actuals))\n",
    "            sub_rmse = np.sqrt(np.mean((sub_preds - sub_actuals)**2))\n",
    "            \n",
    "            print(f\"    {range_name}:\")\n",
    "            print(f\"      Points: {np.sum(range_mask):,} | MAE: {sub_mae:.4f}% | RMSE: {sub_rmse:.4f}%\")\n",
    "            \n",
    "            phase_metrics.append({\n",
    "                'Phase': phase_name,\n",
    "                'Range': range_name,\n",
    "                'MAE': sub_mae,\n",
    "                'RMSE': sub_rmse,\n",
    "                'N Points': np.sum(range_mask)\n",
    "            })\n",
    "\n",
    "# ============================================================\n",
    "# --------------- Partial Curve Testing ----------------------\n",
    "# ============================================================\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"Testing on Partial Charge/Discharge Curves\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "def create_partial_curve(X_seq, y_seq, soc_start, soc_end):\n",
    "    \"\"\"Extract a partial curve from a full charge/discharge sequence.\"\"\"\n",
    "    soc_values = y_seq[:, 0]\n",
    "    \n",
    "    if soc_start < soc_end:  # Charging\n",
    "        mask = (soc_values >= soc_start) & (soc_values <= soc_end)\n",
    "    else:  # Discharging\n",
    "        mask = (soc_values <= soc_start) & (soc_values >= soc_end)\n",
    "    \n",
    "    if np.sum(mask) < 10:\n",
    "        return None, None\n",
    "    \n",
    "    indices = np.where(mask)[0]\n",
    "    start_idx, end_idx = indices[0], indices[-1] + 1\n",
    "    \n",
    "    return X_seq[start_idx:end_idx], y_seq[start_idx:end_idx]\n",
    "\n",
    "partial_curve_tests = [\n",
    "    (0, 30, 'C1ch', 'Charge 0-30%'),\n",
    "    (30, 60, 'C1ch', 'Charge 30-60%'),\n",
    "    (60, 90, 'C1ch', 'Charge 60-90%'),\n",
    "    (20, 80, 'C1ch', 'Charge 20-80%'),\n",
    "    (100, 70, 'C1dc', 'Discharge 100-70%'),\n",
    "    (70, 40, 'C1dc', 'Discharge 70-40%'),\n",
    "    (40, 10, 'C1dc', 'Discharge 40-10%'),\n",
    "    (80, 20, 'C1dc', 'Discharge 80-20%'),\n",
    "]\n",
    "\n",
    "partial_results = []\n",
    "\n",
    "for soc_start, soc_end, phase_type, test_name in partial_curve_tests:\n",
    "    phase_mask = phases_test == phase_type\n",
    "    phase_indices = np.where(phase_mask)[0]\n",
    "    \n",
    "    if len(phase_indices) == 0:\n",
    "        print(f\"\\n{test_name}: No {phase_type} sequences available\")\n",
    "        continue\n",
    "    \n",
    "    test_preds, test_actuals = [], []\n",
    "    valid_sequences = 0\n",
    "    \n",
    "    for idx in phase_indices[:50]:\n",
    "        X_seq = X_test[idx]\n",
    "        y_seq = y_test[idx]\n",
    "        \n",
    "        X_partial, y_partial = create_partial_curve(X_seq, y_seq, soc_start, soc_end)\n",
    "        if X_partial is None:\n",
    "            continue\n",
    "        \n",
    "        valid_sequences += 1\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            x_input = torch.tensor(X_partial[np.newaxis, :, :], dtype=torch.float32, device=device)\n",
    "            pred = model(x_input).cpu().numpy()[0, :, 0] * 100.0\n",
    "        \n",
    "        true = y_partial[:, 0]\n",
    "        \n",
    "        test_preds.append(pred)\n",
    "        test_actuals.append(true)\n",
    "    \n",
    "    if valid_sequences == 0:\n",
    "        print(f\"\\n{test_name}: No valid partial curves found in range\")\n",
    "        continue\n",
    "    \n",
    "    all_preds = np.concatenate(test_preds)\n",
    "    all_actuals = np.concatenate(test_actuals)\n",
    "    \n",
    "    mae_pc = np.mean(np.abs(all_preds - all_actuals))\n",
    "    rmse_pc = np.sqrt(np.mean((all_preds - all_actuals)**2))\n",
    "    max_error_pc = np.max(np.abs(all_preds - all_actuals))\n",
    "    \n",
    "    partial_results.append({\n",
    "        'Test': test_name,\n",
    "        'Phase': phase_type,\n",
    "        'SOC Range': f\"{soc_start}-{soc_end}%\",\n",
    "        'Sequences': valid_sequences,\n",
    "        'Points': len(all_preds),\n",
    "        'MAE': mae_pc,\n",
    "        'RMSE': rmse_pc,\n",
    "        'Max Error': max_error_pc\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{test_name}:\")\n",
    "    print(f\"  Valid Sequences: {valid_sequences}\")\n",
    "    print(f\"  Total Points:    {len(all_preds):,}\")\n",
    "    print(f\"  MAE:             {mae_pc:.4f}%\")\n",
    "    print(f\"  RMSE:            {rmse_pc:.4f}%\")\n",
    "    print(f\"  Max Error:       {max_error_pc:.4f}%\")\n",
    "\n",
    "if len(partial_results) > 0:\n",
    "    partial_df = pd.DataFrame(partial_results)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Partial Curve Testing Summary:\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(partial_df.to_string(index=False))\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# -------------- Visualizations ------------------------------\n",
    "# ============================================================\n",
    "print(\"\\nGenerating visualizations...\")\n",
    "\n",
    "# 1. Partial Curve Visualization\n",
    "fig, axes = plt.subplots(4, 2, figsize=(14, 16))\n",
    "\n",
    "visualization_tests = [\n",
    "    (0, 30, 'C1ch', 'Charge 0-30%', 0, 0),\n",
    "    (30, 60, 'C1ch', 'Charge 30-60%', 0, 1),\n",
    "    (60, 90, 'C1ch', 'Charge 60-90%', 1, 0),\n",
    "    (20, 80, 'C1ch', 'Charge 20-80%', 1, 1),\n",
    "    (100, 70, 'C1dc', 'Discharge 100-70%', 2, 0),\n",
    "    (70, 40, 'C1dc', 'Discharge 70-40%', 2, 1),\n",
    "    (40, 10, 'C1dc', 'Discharge 40-10%', 3, 0),\n",
    "    (80, 20, 'C1dc', 'Discharge 80-20%', 3, 1),\n",
    "]\n",
    "\n",
    "for soc_start, soc_end, phase_type, test_name, row, col in visualization_tests:\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    phase_mask = phases_test == phase_type\n",
    "    phase_indices = np.where(phase_mask)[0]\n",
    "    \n",
    "    found = False\n",
    "    for idx in phase_indices[:100]:\n",
    "        X_seq = X_test[idx]\n",
    "        y_seq = y_test[idx]\n",
    "        \n",
    "        X_partial, y_partial = create_partial_curve(X_seq, y_seq, soc_start, soc_end)\n",
    "        if X_partial is None or len(X_partial) < 10:\n",
    "            continue\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            x_input = torch.tensor(X_partial[np.newaxis, :, :], dtype=torch.float32, device=device)\n",
    "            pred = model(x_input).cpu().numpy()[0, :, 0] * 100.0\n",
    "        \n",
    "        true = y_partial[:, 0]\n",
    "        error = np.abs(true - pred)\n",
    "        mae_pc = np.mean(error)\n",
    "        max_error_pc = np.max(error)\n",
    "        \n",
    "        time_steps = np.arange(len(true))\n",
    "        ax.plot(time_steps, true, 'b-', linewidth=2.5, label='True SOC', alpha=0.8)\n",
    "        ax.plot(time_steps, pred, 'r--', linewidth=2, label='GRU-PINN + Aug', alpha=0.8)\n",
    "        ax.fill_between(time_steps, true, pred, alpha=0.2, color='orange')\n",
    "        \n",
    "        ax.axhline(soc_start, color='green', linestyle=':', linewidth=1.5, alpha=0.7, label=f'Start: {soc_start}%')\n",
    "        ax.axhline(soc_end, color='red', linestyle=':', linewidth=1.5, alpha=0.7, label=f'End: {soc_end}%')\n",
    "        \n",
    "        ax.set_title(f'{test_name}\\nMAE: {mae_pc:.2f}% | Max Error: {max_error_pc:.2f}%', \n",
    "                     fontsize=10, fontweight='bold')\n",
    "        ax.set_xlabel('Time Step', fontsize=9)\n",
    "        ax.set_ylabel('SOC (%)', fontsize=9)\n",
    "        ax.legend(fontsize=7, loc='best')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_ylim(max(0, min(soc_start, soc_end) - 10), \n",
    "                    min(100, max(soc_start, soc_end) + 10))\n",
    "        \n",
    "        found = True\n",
    "        break\n",
    "    \n",
    "    if not found:\n",
    "        ax.text(0.5, 0.5, f'No valid\\n{test_name}\\ndata found',\n",
    "                ha='center', va='center', fontsize=10, transform=ax.transAxes)\n",
    "        ax.set_xlim(0, 1)\n",
    "        ax.set_ylim(0, 1)\n",
    "\n",
    "plt.suptitle('GRU-PINN + Data Augmentation: Partial Curves Performance', \n",
    "             fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Range comparison\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "ax = axes[0, 0]\n",
    "x_pos = np.arange(len(range_metrics))\n",
    "bars = ax.bar(x_pos, [m['MAE'] for m in range_metrics], alpha=0.7, color='steelblue')\n",
    "# Highlight mid-SOC bar\n",
    "bars[1].set_color('orange')\n",
    "bars[1].set_alpha(0.9)\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([m['Range'].split('(')[0].strip() for m in range_metrics], rotation=45, ha='right')\n",
    "ax.set_ylabel('MAE (%)')\n",
    "ax.set_title('MAE by SOC Range (Mid-SOC Improved!)', fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "ax = axes[0, 1]\n",
    "bars = ax.bar(x_pos, [m['RMSE'] for m in range_metrics], alpha=0.7, color='coral')\n",
    "bars[1].set_color('orange')\n",
    "bars[1].set_alpha(0.9)\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([m['Range'].split('(')[0].strip() for m in range_metrics], rotation=45, ha='right')\n",
    "ax.set_ylabel('RMSE (%)')\n",
    "ax.set_title('RMSE by SOC Range', fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "ax = axes[0, 2]\n",
    "bars = ax.bar(x_pos, [m['Max Error'] for m in range_metrics], alpha=0.7, color='lightcoral')\n",
    "bars[1].set_color('orange')\n",
    "bars[1].set_alpha(0.9)\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels([m['Range'].split('(')[0].strip() for m in range_metrics], rotation=45, ha='right')\n",
    "ax.set_ylabel('Max Error (%)')\n",
    "ax.set_title('Max Error by SOC Range', fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "for idx, (soc_min, soc_max, range_name) in enumerate(soc_ranges[:3]):\n",
    "    ax = axes[1, idx]\n",
    "    mask = (actuals >= soc_min) & (actuals <= soc_max)\n",
    "    \n",
    "    if np.sum(mask) > 0:\n",
    "        range_errors = (predictions[mask] - actuals[mask]).flatten()\n",
    "        color = 'orange' if idx == 1 else 'teal'  # Highlight mid-SOC\n",
    "        ax.hist(range_errors, bins=30, edgecolor='black', alpha=0.7, color=color)\n",
    "        ax.axvline(0, color='red', linestyle='--', linewidth=2, label='Zero Error')\n",
    "        ax.set_xlabel('Error (%)')\n",
    "        ax.set_ylabel('Frequency')\n",
    "        title_prefix = '[MID-SOC] ' if idx == 1 else ''\n",
    "        ax.set_title(f'{title_prefix}{range_name}\\nMean Error: {np.mean(range_errors):.3f}%', fontweight='bold')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('GRU-PINN + Augmentation: SOC Range Analysis', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Training complete with data augmentation!\")\n",
    "print(\" Check the mid-SOC (30-60%) metrics - they should be significantly improved!\")\n",
    "print(\"\\nDone!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jawaharram",
   "language": "python",
   "name": "jawaharram"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
